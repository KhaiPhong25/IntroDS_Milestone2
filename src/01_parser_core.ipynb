{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c5706a1",
   "metadata": {},
   "source": [
    "## **Configuration & Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18f54c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports loaded successfully\n",
      "Configuration: RAW_ROOT='../30-paper', INTERMEDIATE_DIR='intermediate'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Configuration & Imports\n",
    "========================\n",
    "Load all required modules and set pipeline configuration.\n",
    "\"\"\"\n",
    "\n",
    "# Standard Library\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "from typing import Dict, List\n",
    "\n",
    "# Third-party\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Project Modules\n",
    "from scanner.dataset_scanner import scan_dataset, save_scan_result\n",
    "from parser.version_resolver import resolve_version\n",
    "from parser.hierarchy_parser import parse_tex_files\n",
    "from parser.reference_extractor import (\n",
    "    extract_references_from_tex_files,\n",
    "    deduplicate_references\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "RAW_ROOT = \"../30-paper\"\n",
    "INTERMEDIATE_DIR = \"intermediate\"\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(INTERMEDIATE_DIR, exist_ok=True)\n",
    "\n",
    "print(\"All imports loaded successfully\")\n",
    "print(f\"Configuration: RAW_ROOT='{RAW_ROOT}', INTERMEDIATE_DIR='{INTERMEDIATE_DIR}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2da0a4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **STEP 0 - Dataset Scanner & Validator**\n",
    "\n",
    "Scan and validate all publication folders to ensure data integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d1de109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 0: Dataset Scanning Complete\n",
      "============================================================\n",
      "  Total publications: 30\n",
      "  Ready publications: 29\n",
      "  Total versions: 42\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STEP 0: Dataset Scanning\n",
    "=========================\n",
    "Scan publication folders for metadata and LaTeX sources.\n",
    "\"\"\"\n",
    "\n",
    "scan_result = scan_dataset(RAW_ROOT)\n",
    "\n",
    "# Summary statistics\n",
    "total_pubs = len(scan_result)\n",
    "ready_pubs = sum(1 for v in scan_result.values() if v[\"status\"] == \"READY\")\n",
    "total_versions = sum(len(v[\"versions\"]) for v in scan_result.values())\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"STEP 0: Dataset Scanning Complete\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"  Total publications: {total_pubs}\")\n",
    "print(f\"  Ready publications: {ready_pubs}\")\n",
    "print(f\"  Total versions: {total_versions}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee73941a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **STEP 1 - Version-level Multi-file Resolver**\n",
    "\n",
    "Resolve multi-file LaTeX structure for each version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07ffb2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221ce1afbeb040bea902051efceb7a49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "STEP 1: Resolving versions:   0%|          | 0/29 [00:00<?, ?pub/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STEP 1 Complete: 42/42 versions resolved\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STEP 1: Version Resolution\n",
    "===========================\n",
    "Resolve LaTeX file dependencies for each version.\n",
    "\"\"\"\n",
    "\n",
    "step1_results = []\n",
    "ready_items = [(pub_id, info) for pub_id, info in scan_result.items() if info[\"status\"] == \"READY\"]\n",
    "\n",
    "for pub_id, info in tqdm(ready_items, desc=\"STEP 1: Resolving versions\", unit=\"pub\"):\n",
    "    for version in info[\"versions\"]:\n",
    "        version_path = f\"{RAW_ROOT}/{pub_id}/tex/{version}\"\n",
    "        result = resolve_version(\n",
    "            publication_id=pub_id,\n",
    "            version_name=version,\n",
    "            version_path=version_path\n",
    "        )\n",
    "        step1_results.append(result)\n",
    "\n",
    "# Summary\n",
    "resolved = sum(1 for r in step1_results if r[\"status\"] == \"RESOLVED\")\n",
    "print(f\"\\nSTEP 1 Complete: {resolved}/{len(step1_results)} versions resolved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea11bbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 42 results to intermediate/step1_results.pkl\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Save STEP 1 Results\n",
    "====================\n",
    "\"\"\"\n",
    "\n",
    "with open(f\"{INTERMEDIATE_DIR}/step1_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(step1_results, f)\n",
    "\n",
    "print(f\"Saved {len(step1_results)} results to {INTERMEDIATE_DIR}/step1_results.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dc8a3e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **STEP 2 - LaTeX Hierarchy Parser**\n",
    "\n",
    "Parse LaTeX files into hierarchical tree structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54d78f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b369c648074ac0b46c93408f50eb77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "STEP 2: Parsing LaTeX:   0%|          | 0/42 [00:00<?, ?version/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STEP 2 Complete: 42 trees parsed\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STEP 2: Hierarchy Parsing\n",
    "==========================\n",
    "Parse LaTeX content into tree structure.\n",
    "\"\"\"\n",
    "\n",
    "parsed_trees = []\n",
    "errors = []\n",
    "\n",
    "for version_info in tqdm(step1_results, desc=\"STEP 2: Parsing LaTeX\", unit=\"version\"):\n",
    "    if version_info[\"status\"] != \"RESOLVED\":\n",
    "        continue\n",
    "    \n",
    "    version_path = f\"{RAW_ROOT}/{version_info['publication_id']}/tex/{version_info['version']}\"\n",
    "    \n",
    "    try:\n",
    "        root_node = parse_tex_files(\n",
    "            version_path=version_path,\n",
    "            tex_files=version_info[\"used_tex_files\"]\n",
    "        )\n",
    "        parsed_trees.append({\n",
    "            \"publication_id\": version_info[\"publication_id\"],\n",
    "            \"version\": version_info[\"version\"],\n",
    "            \"root\": root_node\n",
    "        })\n",
    "    except Exception as e:\n",
    "        errors.append(f\"{version_info['publication_id']}/{version_info['version']}: {str(e)}\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\nSTEP 2 Complete: {len(parsed_trees)} trees parsed\")\n",
    "if errors:\n",
    "    print(f\"{len(errors)} errors encountered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55d126df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 42 trees to intermediate/parsed_trees.pkl\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Save STEP 2 Results\n",
    "====================\n",
    "\"\"\"\n",
    "\n",
    "with open(f\"{INTERMEDIATE_DIR}/parsed_trees.pkl\", \"wb\") as f:\n",
    "    pickle.dump(parsed_trees, f)\n",
    "\n",
    "print(f\"Saved {len(parsed_trees)} trees to {INTERMEDIATE_DIR}/parsed_trees.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2321f72",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **STEP 2.5 - Raw Reference Extraction**\n",
    "\n",
    "Extract bibliography entries from LaTeX sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67d71721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cbabfb2d64c401692be0e78d11d1e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "STEP 2.5: Extracting references:   0%|          | 0/42 [00:00<?, ?version/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Parsing .bib file: ../30-paper/2211-13748/tex/2211-13748v1\\mybibliography.bib\n",
      "[INFO] Parsing .bib file: ../30-paper/2211-13750/tex/2211-13750v1\\comparingsinglettestingschemes.bib\n",
      "[INFO] Parsing .bib file: ../30-paper/2211-13750/tex/2211-13750v2\\comparingsinglettestingschemes4.bib\n",
      "[INFO] Parsing .bib file: ../30-paper/2211-13751/tex/2211-13751v1\\bibliography_v3.bib\n",
      "[INFO] Parsing .bib file: ../30-paper/2211-13752/tex/2211-13752v1\\egbib.bib\n",
      "[INFO] Parsing .bib file: ../30-paper/2211-13754/tex/2211-13754v1\\refs.bib\n",
      "[WARN] Bibliography file not found: ../30-paper/2211-13755/tex/2211-13755v1\\egbib.bib\n",
      "[INFO] Parsing .bib file: ../30-paper/2211-13755/tex/2211-13755v2\\egbib.bib\n",
      "[INFO] Parsing .bib file: ../30-paper/2211-13757/tex/2211-13757v1\\bib.bib\n",
      "[INFO] Parsing .bib file: ../30-paper/2211-13757/tex/2211-13757v2\\bib.bib\n",
      "[WARN] Bibliography file not found: ../30-paper/2211-13758/tex/2211-13758v1\\example.bib\n",
      "[INFO] Parsing .bib file: ../30-paper/2211-13758/tex/2211-13758v1\\bibliography.bib\n",
      "[INFO] Parsing .bib file: ../30-paper/2211-13759/tex/2211-13759v1\\thisbibliography.bib\n",
      "[INFO] Parsing .bib file: ../30-paper/2211-13759/tex/2211-13759v2\\thisbibliography.bib\n",
      "[INFO] Parsing .bib file: ../30-paper/2211-13760/tex/2211-13760v1\\references.bib\n",
      "[INFO] Parsing .bib file: ../30-paper/2211-13760/tex/2211-13760v2\\references.bib\n",
      "[INFO] Parsing .bib file: ../30-paper/2211-13761/tex/2211-13761v1\\references.bib\n",
      "[INFO] Parsing .bib file: ../30-paper/2211-13762/tex/2211-13762v1\\egbib.bib\n",
      "[INFO] Parsing .bib file: ../30-paper/2211-13762/tex/2211-13762v2\\egbib.bib\n",
      "[INFO] Parsing .bib file: ../30-paper/2211-13764/tex/2211-13764v1\\biblio.bib\n",
      "[WARN] Bibliography file not found: ../30-paper/2211-13765/tex/2211-13765v1\\references.bib\n",
      "[INFO] Parsing .bib file: ../30-paper/2211-13766/tex/2211-13766v1\\apssamp.bib\n",
      "[INFO] Parsing .bib file: ../30-paper/2211-13766/tex/2211-13766v2\\apssamp.bib\n",
      "[INFO] Parsing .bib file: ../30-paper/2211-13766/tex/2211-13766v3\\apssamp.bib\n",
      "[INFO] Parsing .bib file: ../30-paper/2211-13767/tex/2211-13767v1\\references.bib\n",
      "[INFO] Parsing .bib file: ../30-paper/2211-13768/tex/2211-13768v1\\reference.bib\n",
      "[INFO] Parsing .bib file: ../30-paper/2211-13768/tex/2211-13768v2\\reference.bib\n",
      "[WARN] Bibliography file not found: ../30-paper/2211-13769/tex/2211-13769v1\\strings,refs.bib\n",
      "[INFO] Parsing .bib file: ../30-paper/2211-13769/tex/2211-13769v1\\egbib.bib\n",
      "[INFO] Parsing .bib file: ../30-paper/2211-13771/tex/2211-13771v1\\paper.bib\n",
      "[WARN] Bibliography file not found: ../30-paper/2211-13772/tex/2211-13772v1\\refs.bib\n",
      "[WARN] Bibliography file not found: ../30-paper/2211-13773/tex/2211-13773v1\\IEEEfull,trasfer.bib\n",
      "[WARN] Bibliography file not found: ../30-paper/2211-13773/tex/2211-13773v2\\IEEEfull,trasfer.bib\n",
      "[INFO] Parsing .bib file: ../30-paper/2211-13774/tex/2211-13774v1\\References.bib\n",
      "[INFO] Parsing .bib file: ../30-paper/2211-13775/tex/2211-13775v1\\references.bib\n",
      "[INFO] Parsing .bib file: ../30-paper/2211-13775/tex/2211-13775v2\\egbib.bib\n",
      "[INFO] Parsing .bib file: ../30-paper/2211-13776/tex/2211-13776v1\\acl2020.bib\n",
      "\n",
      "STEP 2.5 Complete:\n",
      "  - Publications with references: 24\n",
      "  - Total unique references: 1946\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STEP 2.5: Reference Extraction\n",
    "===============================\n",
    "Extract BibTeX references from LaTeX files.\n",
    "\"\"\"\n",
    "\n",
    "raw_references = {}\n",
    "\n",
    "for version_info in tqdm(step1_results, desc=\"STEP 2.5: Extracting references\", unit=\"version\"):\n",
    "    if version_info[\"status\"] != \"RESOLVED\":\n",
    "        continue\n",
    "    \n",
    "    pub_id = version_info[\"publication_id\"]\n",
    "    version_path = f\"{RAW_ROOT}/{pub_id}/tex/{version_info['version']}\"\n",
    "    \n",
    "    try:\n",
    "        references = extract_references_from_tex_files(\n",
    "            version_path=version_path,\n",
    "            tex_files=version_info[\"used_tex_files\"]\n",
    "        )\n",
    "        if references:\n",
    "            if pub_id not in raw_references:\n",
    "                raw_references[pub_id] = []\n",
    "            raw_references[pub_id].extend(references)\n",
    "    except Exception as e:\n",
    "        pass  # Silent fail\n",
    "\n",
    "# Deduplicate per publication\n",
    "deduplicated_references = {\n",
    "    pub_id: deduplicate_references(refs)\n",
    "    for pub_id, refs in raw_references.items()\n",
    "}\n",
    "\n",
    "# Summary\n",
    "total_refs = sum(len(refs) for refs in deduplicated_references.values())\n",
    "print(f\"\\nSTEP 2.5 Complete:\")\n",
    "print(f\"  - Publications with references: {len(deduplicated_references)}\")\n",
    "print(f\"  - Total unique references: {total_refs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70211cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 24 reference sets to intermediate/raw_references.pkl\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Save STEP 2.5 Results\n",
    "======================\n",
    "\"\"\"\n",
    "\n",
    "with open(f\"{INTERMEDIATE_DIR}/raw_references.pkl\", \"wb\") as f:\n",
    "    pickle.dump(deduplicated_references, f)\n",
    "\n",
    "print(f\"Saved {len(deduplicated_references)} reference sets to {INTERMEDIATE_DIR}/raw_references.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
