{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d55b6fc",
   "metadata": {},
   "source": [
    "## **Configuration & Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d94d2363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports loaded successfully\n",
      "Configuration: RAW_ROOT='../30-paper', INTERMEDIATE_DIR='intermediate'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Configuration & Imports\n",
    "========================\n",
    "Load all required modules and set pipeline configuration.\n",
    "\"\"\"\n",
    "\n",
    "# Standard Library\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "# Third-party\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Project Modules\n",
    "from matcher.reference_cleaner import clean_bibtex_entry, clean_arxiv_reference\n",
    "from matcher.reference_matcher import find_best_match, compute_match_score\n",
    "from scanner.dataset_scanner import scan_dataset\n",
    "\n",
    "# Configuration\n",
    "RAW_ROOT = \"../30-paper\"\n",
    "INTERMEDIATE_DIR = \"intermediate\"\n",
    "OUTPUT_DIR = \"output\"\n",
    "MANUAL_LABELS_FILE = \"manual_groundtruth.json\"\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"All imports loaded successfully\")\n",
    "print(f\"Configuration: RAW_ROOT='{RAW_ROOT}', INTERMEDIATE_DIR='{INTERMEDIATE_DIR}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392dfe52",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **STEP 4.0 - Load References Data**\n",
    "\n",
    "Load both BibTeX references and arXiv database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d68bc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STEP 4.0 Complete:\n",
      "  - BibTeX entries: 1946 from 24 publications\n",
      "  - arXiv entries: 795 from 30 publications\n",
      "  - Publications with both: 24\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STEP 4.0: Load References for Matching\n",
    "========================================\n",
    "Load BibTeX and arXiv references.\n",
    "\"\"\"\n",
    "\n",
    "# Load BibTeX references from preprocessing\n",
    "if os.path.exists(f\"{INTERMEDIATE_DIR}/step3_final_references.pkl\"):\n",
    "    with open(f\"{INTERMEDIATE_DIR}/step3_final_references.pkl\", \"rb\") as f:\n",
    "        bibtex_references = pickle.load(f)\n",
    "else:\n",
    "    print(\"ERROR: step3_final_references.pkl not found. Run 02_data_preprocessing.ipynb first.\")\n",
    "    bibtex_references = {}\n",
    "\n",
    "# Scan dataset for arXiv references\n",
    "scan_result = scan_dataset(RAW_ROOT)\n",
    "\n",
    "# Load arXiv references from references.json\n",
    "arxiv_references = {}\n",
    "for pub_id in scan_result.keys():\n",
    "    ref_path = os.path.join(RAW_ROOT, pub_id, \"references.json\")\n",
    "    if os.path.exists(ref_path):\n",
    "        with open(ref_path, 'r', encoding='utf-8') as f:\n",
    "            refs = json.load(f)\n",
    "            ref_list = [{'arxiv_id': arxiv_id, **ref_data} for arxiv_id, ref_data in refs.items()]\n",
    "            arxiv_references[pub_id] = ref_list\n",
    "\n",
    "# Summary\n",
    "total_bibtex = sum(len(refs) for refs in bibtex_references.values())\n",
    "total_arxiv = sum(len(refs) for refs in arxiv_references.values())\n",
    "common_pubs = len(set(bibtex_references.keys()) & set(arxiv_references.keys()))\n",
    "\n",
    "print(f\"\\nSTEP 4.0 Complete:\")\n",
    "print(f\"  - BibTeX entries: {total_bibtex} from {len(bibtex_references)} publications\")\n",
    "print(f\"  - arXiv entries: {total_arxiv} from {len(arxiv_references)} publications\")\n",
    "print(f\"  - Publications with both: {common_pubs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9021fb7c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **STEP 4.1 - Data Cleaning**\n",
    "\n",
    "Normalize and clean both BibTeX and arXiv references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61e77528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c17a35c54a84a5f8b25ebc7b706acbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cleaning BibTeX:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a3118984fb4adf9db00894d9e53d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cleaning arXiv:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STEP 4.1 Complete: Cleaned 2741 entries\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STEP 4.1: Data Cleaning\n",
    "========================\n",
    "Normalize text for matching algorithms.\n",
    "\"\"\"\n",
    "\n",
    "cleaned_bibtex = {\n",
    "    pub_id: [clean_bibtex_entry(ref) for ref in refs]\n",
    "    for pub_id, refs in tqdm(bibtex_references.items(), desc=\"Cleaning BibTeX\", leave=False)\n",
    "}\n",
    "\n",
    "cleaned_arxiv = {\n",
    "    pub_id: [clean_arxiv_reference(ref) for ref in refs]\n",
    "    for pub_id, refs in tqdm(arxiv_references.items(), desc=\"Cleaning arXiv\", leave=False)\n",
    "}\n",
    "\n",
    "total_cleaned = sum(len(refs) for refs in cleaned_bibtex.values()) + sum(len(refs) for refs in cleaned_arxiv.values())\n",
    "print(f\"\\nSTEP 4.1 Complete: Cleaned {total_cleaned} entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e1ed32",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **STEP 4.2 - Automatic Heuristic Matching**\n",
    "\n",
    "Use string similarity algorithms to match references.\n",
    "\n",
    "**Algorithms:**\n",
    "- Levenshtein distance\n",
    "- Jaccard similarity\n",
    "- SequenceMatcher\n",
    "- Author overlap\n",
    "- Year matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97fefc08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d797af6af641447b814eaba56e9e5dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "STEP 4.2: Automatic matching:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STEP 4.2 Complete:\n",
      "  - Matched: 83/1946 (4.3%)\n",
      "  - High confidence (≥0.8): 33\n",
      "  - Medium confidence (0.6-0.8): 50\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STEP 4.2: Automatic Matching\n",
    "=============================\n",
    "Use string similarity to match BibTeX with arXiv.\n",
    "\"\"\"\n",
    "\n",
    "automatic_matches = {}\n",
    "match_statistics = {\n",
    "    'total_bibtex': 0,\n",
    "    'matched': 0,\n",
    "    'unmatched': 0,\n",
    "    'high_confidence': 0,  # ≥0.8\n",
    "    'medium_confidence': 0,  # 0.6-0.8\n",
    "}\n",
    "\n",
    "for pub_id in tqdm(cleaned_bibtex.keys(), desc=\"STEP 4.2: Automatic matching\", leave=False):\n",
    "    if pub_id not in cleaned_arxiv:\n",
    "        continue\n",
    "    \n",
    "    bibtex_entries = cleaned_bibtex[pub_id]\n",
    "    arxiv_refs = cleaned_arxiv[pub_id]\n",
    "    matches = []\n",
    "    \n",
    "    for bib_entry in bibtex_entries:\n",
    "        match_statistics['total_bibtex'] += 1\n",
    "        \n",
    "        result = find_best_match(bib_entry, arxiv_refs, threshold=0.6)\n",
    "        \n",
    "        if result:\n",
    "            arxiv_id, score, breakdown = result\n",
    "            matches.append({\n",
    "                'bibtex_key': bib_entry['key'],\n",
    "                'bibtex_ref_id': bib_entry.get('ref_id', ''),\n",
    "                'arxiv_id': arxiv_id,\n",
    "                'confidence_score': score,\n",
    "                'score_breakdown': breakdown,\n",
    "                'bibtex_title': bib_entry['raw_title'],\n",
    "                'bibtex_authors': bib_entry['raw_author'],\n",
    "                'bibtex_year': bib_entry['raw_year'],\n",
    "                'match_type': 'automatic'\n",
    "            })\n",
    "            match_statistics['matched'] += 1\n",
    "            if score >= 0.8:\n",
    "                match_statistics['high_confidence'] += 1\n",
    "            else:\n",
    "                match_statistics['medium_confidence'] += 1\n",
    "        else:\n",
    "            match_statistics['unmatched'] += 1\n",
    "    \n",
    "    if matches:\n",
    "        automatic_matches[pub_id] = matches\n",
    "\n",
    "# Summary\n",
    "match_rate = match_statistics['matched']/match_statistics['total_bibtex']*100 if match_statistics['total_bibtex'] > 0 else 0\n",
    "print(f\"\\nSTEP 4.2 Complete:\")\n",
    "print(f\"  - Matched: {match_statistics['matched']}/{match_statistics['total_bibtex']} ({match_rate:.1f}%)\")\n",
    "print(f\"  - High confidence (≥0.8): {match_statistics['high_confidence']}\")\n",
    "print(f\"  - Medium confidence (0.6-0.8): {match_statistics['medium_confidence']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f25669b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **STEP 4.3 - Manual Labeling Integration**\n",
    "\n",
    "Load manual ground truth labels if available.\n",
    "\n",
    "**Requirements:**\n",
    "- ≥5 publications\n",
    "- ≥20 labeled reference pairs\n",
    "\n",
    "**Note:** If `manual_groundtruth.json` doesn't exist, you can:\n",
    "1. Create it manually by editing the JSON file\n",
    "2. Use the interactive labeling tool from main.ipynb\n",
    "3. Generate sample labels from high-confidence automatic matches (for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4322c386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual_groundtruth.json not found. Using automatic matches only.\n",
      "  To create manual labels:\n",
      "  1. Run interactive labeler in main.ipynb\n",
      "  2. Or create manual_groundtruth.json manually\n",
      "  Generated 7 pseudo-manual labels for testing\n",
      "\n",
      "STEP 4.3 Complete: 7 labels from 3 publications\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STEP 4.3: Load Manual Labels\n",
    "==============================\n",
    "Load manually verified ground truth labels.\n",
    "\"\"\"\n",
    "\n",
    "manual_labels_list = []\n",
    "\n",
    "# Try to load manual ground truth\n",
    "if os.path.exists(MANUAL_LABELS_FILE):\n",
    "    with open(MANUAL_LABELS_FILE, 'r', encoding='utf-8') as f:\n",
    "        manual_labels_dict = json.load(f)\n",
    "    \n",
    "    # Convert from dict format to list format\n",
    "    for pub_id, labels in manual_labels_dict.items():\n",
    "        for bib_key, arxiv_id in labels.items():\n",
    "            manual_labels_list.append({\n",
    "                'pub_id': pub_id,\n",
    "                'bibtex_key': bib_key,\n",
    "                'arxiv_id': arxiv_id,\n",
    "                'match_type': 'manual',\n",
    "                'confidence': 'verified'\n",
    "            })\n",
    "    \n",
    "    manual_pubs = len(manual_labels_dict)\n",
    "    manual_count = len(manual_labels_list)\n",
    "    print(f\"Loaded {manual_count} manual labels from {manual_pubs} publications\")\n",
    "else:\n",
    "    print(f\"{MANUAL_LABELS_FILE} not found. Using automatic matches only.\")\n",
    "    print(f\"  To create manual labels:\")\n",
    "    print(f\"  1. Run interactive labeler in main.ipynb\")\n",
    "    print(f\"  2. Or create {MANUAL_LABELS_FILE} manually\")\n",
    "    \n",
    "    # Generate sample labels from high-confidence matches for testing\n",
    "    sample_labels = []\n",
    "    for pub_id, matches in list(automatic_matches.items())[:5]:\n",
    "        high_conf = [m for m in matches if m['confidence_score'] >= 0.85][:5]\n",
    "        for match in high_conf:\n",
    "            sample_labels.append({\n",
    "                'pub_id': pub_id,\n",
    "                'bibtex_key': match['bibtex_key'],\n",
    "                'bibtex_ref_id': match['bibtex_ref_id'],\n",
    "                'arxiv_id': match['arxiv_id'],\n",
    "                'match_type': 'pseudo_manual',\n",
    "                'confidence': 'auto_generated',\n",
    "                'auto_score': match['confidence_score'],\n",
    "                'notes': 'Auto-generated from high-confidence matches - NOT VERIFIED'\n",
    "            })\n",
    "            if len(sample_labels) >= 20:\n",
    "                break\n",
    "        if len(sample_labels) >= 20:\n",
    "            break\n",
    "    \n",
    "    manual_labels_list = sample_labels\n",
    "    print(f\"  Generated {len(sample_labels)} pseudo-manual labels for testing\")\n",
    "\n",
    "# Summary\n",
    "manual_pubs = len(set(l['pub_id'] for l in manual_labels_list))\n",
    "print(f\"\\nSTEP 4.3 Complete: {len(manual_labels_list)} labels from {manual_pubs} publications\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d928acfd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **STEP 4.4 - Combine All Matches**\n",
    "\n",
    "Merge automatic and manual matches (manual labels override automatic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1eea19e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STEP 4.4 Complete:\n",
      "  - Total matches: 83\n",
      "  - Manual: 7, Automatic: 76\n",
      "  - Publications: 16\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STEP 4.4: Combine Matches\n",
    "==========================\n",
    "Merge automatic and manual matches with priority.\n",
    "\"\"\"\n",
    "\n",
    "final_matches = {}\n",
    "\n",
    "# Start with automatic matches\n",
    "for pub_id, matches in automatic_matches.items():\n",
    "    final_matches[pub_id] = matches.copy()\n",
    "\n",
    "# Override with manual labels (higher priority)\n",
    "for label in manual_labels_list:\n",
    "    pub_id = label['pub_id']\n",
    "    \n",
    "    if pub_id not in final_matches:\n",
    "        final_matches[pub_id] = []\n",
    "    \n",
    "    # Remove automatic match for same key if exists\n",
    "    final_matches[pub_id] = [m for m in final_matches[pub_id] if m['bibtex_key'] != label['bibtex_key']]\n",
    "    \n",
    "    # Add manual label\n",
    "    final_matches[pub_id].append({\n",
    "        'bibtex_key': label['bibtex_key'],\n",
    "        'bibtex_ref_id': label.get('bibtex_ref_id', ''),\n",
    "        'arxiv_id': label['arxiv_id'],\n",
    "        'confidence_score': 1.0,\n",
    "        'match_type': label.get('match_type', 'manual'),\n",
    "        'confidence': label.get('confidence', 'verified'),\n",
    "        'notes': label.get('notes', '')\n",
    "    })\n",
    "\n",
    "# Summary\n",
    "total_matches = sum(len(m) for m in final_matches.values())\n",
    "manual_count = sum(1 for m in final_matches.values() for x in m if x['match_type'] in ['manual', 'pseudo_manual'])\n",
    "auto_count = total_matches - manual_count\n",
    "\n",
    "print(f\"\\nSTEP 4.4 Complete:\")\n",
    "print(f\"  - Total matches: {total_matches}\")\n",
    "print(f\"  - Manual: {manual_count}, Automatic: {auto_count}\")\n",
    "print(f\"  - Publications: {len(final_matches)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3977c36d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **STEP 4.5 - Export Final Results**\n",
    "\n",
    "Save matched references and manual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2729561a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved matched references to:\n",
      "  - step4_matched_references.pkl\n",
      "  - step4_matched_references.json\n",
      "  - step4_manual_labels.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STEP 4.5: Save Final Results\n",
    "=============================\n",
    "Export matched references to JSON.\n",
    "\"\"\"\n",
    "\n",
    "# Save matched references\n",
    "with open(\"step4_matched_references.pkl\", \"wb\") as f:\n",
    "    pickle.dump(final_matches, f)\n",
    "\n",
    "with open(\"step4_matched_references.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_matches, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Save manual labels\n",
    "with open(\"step4_manual_labels.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(manual_labels_list, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Saved matched references to:\")\n",
    "print(f\"  - step4_matched_references.pkl\")\n",
    "print(f\"  - step4_matched_references.json\")\n",
    "print(f\"  - step4_manual_labels.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b67ddc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **STEP 4.6 - Requirements Validation**\n",
    "\n",
    "Check if all project requirements are met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f764f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "REFERENCE MATCHING PIPELINE - REQUIREMENT CHECK\n",
      "================================================================================\n",
      "\n",
      "✓ 1. Data Cleaning: COMPLETED\n",
      "   - Normalized 1946 BibTeX + 795 arXiv entries\n",
      "\n",
      "✗ 2. Manual Labeling:\n",
      "   - Publications: 3/5 ✗\n",
      "   - Reference pairs: 7/20 ✗\n",
      "   ⚠ Use interactive labeling tool or create manual_groundtruth.json\n",
      "\n",
      "✗ 3. Automatic Matching:\n",
      "   - Total entries: 1946\n",
      "   - Matched: 83 (4.3%)\n",
      "   - Required (10%): 195 ✗\n",
      "\n",
      "✓ 4. Algorithms Implemented:\n",
      "   - Levenshtein distance, Jaccard similarity, SequenceMatcher\n",
      "   - Author overlap, Year matching, Combined scoring\n",
      "\n",
      "================================================================================\n",
      "⚠ SOME REQUIREMENTS NOT MET\n",
      "  - Need more manual labels\n",
      "  - Need more automatic matches\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STEP 4.6: Requirements Validation\n",
    "===================================\n",
    "Verify all project requirements are satisfied.\n",
    "\"\"\"\n",
    "\n",
    "manual_pubs = len(set(l['pub_id'] for l in manual_labels_list))\n",
    "manual_pairs = len(manual_labels_list)\n",
    "total_refs = match_statistics['total_bibtex']\n",
    "auto_matched = match_statistics['matched']\n",
    "required_10pct = total_refs * 0.1\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"REFERENCE MATCHING PIPELINE - REQUIREMENT CHECK\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Requirement 1: Data Cleaning\n",
    "print(f\"\\n✓ 1. Data Cleaning: COMPLETED\")\n",
    "print(f\"   - Normalized {total_bibtex} BibTeX + {total_arxiv} arXiv entries\")\n",
    "\n",
    "# Requirement 2: Manual Labeling\n",
    "req2_met = manual_pairs >= 20 and manual_pubs >= 5\n",
    "status2 = '✓' if req2_met else '✗'\n",
    "print(f\"\\n{status2} 2. Manual Labeling:\")\n",
    "print(f\"   - Publications: {manual_pubs}/5 {'✓' if manual_pubs >= 5 else '✗'}\")\n",
    "print(f\"   - Reference pairs: {manual_pairs}/20 {'✓' if manual_pairs >= 20 else '✗'}\")\n",
    "if not req2_met:\n",
    "    print(f\"   ⚠ Use interactive labeling tool or create manual_groundtruth.json\")\n",
    "\n",
    "# Requirement 3: Automatic Matching\n",
    "req3_met = auto_matched >= required_10pct\n",
    "status3 = '✓' if req3_met else '✗'\n",
    "print(f\"\\n{status3} 3. Automatic Matching:\")\n",
    "print(f\"   - Total entries: {total_refs}\")\n",
    "print(f\"   - Matched: {auto_matched} ({auto_matched/total_refs*100:.1f}%)\")\n",
    "print(f\"   - Required (10%): {required_10pct:.0f} {'✓' if req3_met else '✗'}\")\n",
    "\n",
    "# Requirement 4: Algorithms\n",
    "print(f\"\\n✓ 4. Algorithms Implemented:\")\n",
    "print(f\"   - Levenshtein distance, Jaccard similarity, SequenceMatcher\")\n",
    "print(f\"   - Author overlap, Year matching, Combined scoring\")\n",
    "\n",
    "# Overall Status\n",
    "all_met = req2_met and req3_met\n",
    "print(f\"\\n{'='*80}\")\n",
    "if all_met:\n",
    "    print(f\"✓ ALL REQUIREMENTS MET\")\n",
    "else:\n",
    "    print(f\"⚠ SOME REQUIREMENTS NOT MET\")\n",
    "    if not req2_met:\n",
    "        print(f\"  - Need more manual labels\")\n",
    "    if not req3_met:\n",
    "        print(f\"  - Need more automatic matches\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5e44c4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Pipeline Summary**\n",
    "\n",
    "Final summary of the matching pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ecb3382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "03_DATA_MODELING PIPELINE - SUMMARY\n",
      "================================================================================\n",
      "STEP 4.0: Loaded 1946 BibTeX + 795 arXiv references\n",
      "STEP 4.1: Cleaned 2741 entries\n",
      "STEP 4.2: Automatic matching - 4.3% match rate\n",
      "STEP 4.3: Loaded 7 manual labels\n",
      "STEP 4.4: Combined 83 total matches\n",
      "STEP 4.5: Exported results to JSON\n",
      "STEP 4.6: Requirements validation complete\n",
      "\n",
      "All outputs saved to current directory\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pipeline Summary\n",
    "=================\n",
    "\"\"\"\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"03_DATA_MODELING PIPELINE - SUMMARY\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"STEP 4.0: Loaded {total_bibtex} BibTeX + {total_arxiv} arXiv references\")\n",
    "print(f\"STEP 4.1: Cleaned {total_cleaned} entries\")\n",
    "print(f\"STEP 4.2: Automatic matching - {match_rate:.1f}% match rate\")\n",
    "print(f\"STEP 4.3: Loaded {len(manual_labels_list)} manual labels\")\n",
    "print(f\"STEP 4.4: Combined {total_matches} total matches\")\n",
    "print(f\"STEP 4.5: Exported results to JSON\")\n",
    "print(f\"STEP 4.6: Requirements validation complete\")\n",
    "print(f\"\\nAll outputs saved to current directory\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd5c14c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Optional: Interactive Labeling Tool**\n",
    "\n",
    "If you need to create manual ground truth labels, uncomment and run the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eecbc75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Interactive Labeling Tool\n",
    "# ==========================\n",
    "# Uncomment to use interactive labeling.\n",
    "# \"\"\"\n",
    "\n",
    "# import random\n",
    "\n",
    "# class InteractiveLabeler:\n",
    "#     \"\"\"Interactive labeling tool with auto-save and resume capability.\"\"\"\n",
    "#     \n",
    "#     def __init__(self, \n",
    "#                  bibtex_refs: Dict[str, List[Dict]],\n",
    "#                  arxiv_refs: Dict[str, List[Dict]],\n",
    "#                  output_file: str = \"manual_groundtruth.json\"):\n",
    "#         self.bibtex_refs = bibtex_refs\n",
    "#         self.arxiv_refs = arxiv_refs\n",
    "#         self.output_file = output_file\n",
    "#         self.labels = {}\n",
    "#         self._load_existing_labels()\n",
    "#     \n",
    "#     def _load_existing_labels(self):\n",
    "#         if os.path.exists(self.output_file):\n",
    "#             with open(self.output_file, 'r', encoding='utf-8') as f:\n",
    "#                 self.labels = json.load(f)\n",
    "#             total = sum(len(v) for v in self.labels.values())\n",
    "#             print(f\"Loaded {total} existing labels from {len(self.labels)} pubs\")\n",
    "#     \n",
    "#     def _save_labels(self):\n",
    "#         with open(self.output_file, 'w', encoding='utf-8') as f:\n",
    "#             json.dump(self.labels, f, indent=2, ensure_ascii=False)\n",
    "#         total = sum(len(v) for v in self.labels.values())\n",
    "#         print(f\"Saved {total} labels from {len(self.labels)} pubs\")\n",
    "#     \n",
    "#     def _generate_candidates(self, bibtex_entry, arxiv_pool, top_k=5):\n",
    "#         candidates = []\n",
    "#         for arxiv_ref in arxiv_pool:\n",
    "#             score = compute_match_score(bibtex_entry, arxiv_ref)\n",
    "#             candidates.append((arxiv_ref, score, {}))\n",
    "#         candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "#         return candidates[:top_k]\n",
    "#     \n",
    "#     def run(self, pub_ids=None, num_pubs=5, refs_per_pub=5):\n",
    "#         if pub_ids is None:\n",
    "#             valid_pubs = list(set(self.bibtex_refs.keys()) & set(self.arxiv_refs.keys()))\n",
    "#             pub_ids = random.sample(valid_pubs, min(num_pubs, len(valid_pubs)))\n",
    "#         \n",
    "#         print(f\"Starting interactive labeling for {len(pub_ids)} publications...\")\n",
    "#         print(f\"Target: ~{refs_per_pub} references per publication\")\n",
    "#         \n",
    "#         for pub_id in pub_ids:\n",
    "#             print(f\"\\n{'='*80}\")\n",
    "#             print(f\"Publication: {pub_id}\")\n",
    "#             print(f\"{'='*80}\")\n",
    "#             \n",
    "#             if pub_id not in self.labels:\n",
    "#                 self.labels[pub_id] = {}\n",
    "#             \n",
    "#             bibtex_entries = self.bibtex_refs[pub_id][:refs_per_pub]\n",
    "#             arxiv_pool = self.arxiv_refs[pub_id]\n",
    "#             \n",
    "#             for bib_entry in bibtex_entries:\n",
    "#                 bib_key = bib_entry['key']\n",
    "#                 if bib_key in self.labels[pub_id]:\n",
    "#                     continue\n",
    "#                 \n",
    "#                 print(f\"\\nBibTeX: {bib_entry['raw_title'][:60]}...\")\n",
    "#                 candidates = self._generate_candidates(bib_entry, arxiv_pool)\n",
    "#                 \n",
    "#                 for i, (arxiv_ref, score, _) in enumerate(candidates, 1):\n",
    "#                     print(f\"[{i}] {score:.3f} - {arxiv_ref.get('arxiv_id', 'N/A')}\")\n",
    "#                 \n",
    "#                 choice = input(\"Select [1-5], s=skip, q=quit: \").strip().lower()\n",
    "#                 \n",
    "#                 if choice == 'q':\n",
    "#                     self._save_labels()\n",
    "#                     return self.labels\n",
    "#                 elif choice == 's':\n",
    "#                     continue\n",
    "#                 elif choice.isdigit() and 1 <= int(choice) <= len(candidates):\n",
    "#                     arxiv_id = candidates[int(choice)-1][0]['arxiv_id']\n",
    "#                     self.labels[pub_id][bib_key] = arxiv_id\n",
    "#                     print(f\"Labeled: {bib_key} -> {arxiv_id}\")\n",
    "#             \n",
    "#             self._save_labels()\n",
    "#         \n",
    "#         return self.labels\n",
    "\n",
    "# # Usage:\n",
    "# # labeler = InteractiveLabeler(cleaned_bibtex, cleaned_arxiv)\n",
    "# # manual_labels = labeler.run(num_pubs=5, refs_per_pub=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
