{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c08ea80b",
   "metadata": {},
   "source": [
    "## **Configuration & Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c6a66e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports loaded successfully\n",
      "Configuration: RAW_ROOT='../../30-paper', INTERMEDIATE_DIR='intermediate', OUTPUT_DIR='../22127XXX'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Configuration & Imports\n",
    "========================\n",
    "Load all required modules and set pipeline configuration.\n",
    "\"\"\"\n",
    "\n",
    "# Standard Library\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "# Add src directory to Python path\n",
    "current_dir = os.getcwd()\n",
    "if current_dir not in sys.path:\n",
    "    sys.path.insert(0, current_dir)\n",
    "\n",
    "# Third-party\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Project Modules - Parser\n",
    "from parser.node_normalizer import normalize_node, cleanup_latex\n",
    "from parser.id_assigner import assign_ids\n",
    "from parser.content_index import build_content_index\n",
    "from parser.deduplicator import deduplicate_tree\n",
    "from parser.reference_extractor import deduplicate_references\n",
    "\n",
    "# Project Modules - Matcher\n",
    "from matcher.reference_cleaner import clean_bibtex_entry, clean_arxiv_reference\n",
    "from matcher.reference_matcher import find_best_match, calculate_similarity_components, find_hard_negative\n",
    "\n",
    "# Configuration\n",
    "RAW_ROOT = \"../../30-paper\"\n",
    "INTERMEDIATE_DIR = \"intermediate\"\n",
    "STUDENT_ID = \"22127XXX\"  # TODO: Change to your student ID\n",
    "OUTPUT_DIR = f\"../{STUDENT_ID}\"  # Submission folder structure\n",
    "MANUAL_LABELS_FILE = \"manual_groundtruth.json\"\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(INTERMEDIATE_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"All imports loaded successfully\")\n",
    "print(f\"Configuration: RAW_ROOT='{RAW_ROOT}', INTERMEDIATE_DIR='{INTERMEDIATE_DIR}', OUTPUT_DIR='{OUTPUT_DIR}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2ec9e2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **STEP 1 - Load Intermediate Data**\n",
    "\n",
    "Load parsed trees, references, and arXiv database from previous pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d733f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c57149b7b2a4ca7969da5c756318e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "STEP 1: Loading arXiv database:   0%|          | 0/42 [00:00<?, ?pub/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 1: Data Loading Complete\n",
      "================================================================================\n",
      "  Total publications: 42\n",
      "  Raw references: 1946\n",
      "  arXiv entries: 781\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STEP 1: Load Intermediate Data\n",
    "================================\n",
    "Load parsed trees and references from Parser Core pipeline.\n",
    "\"\"\"\n",
    "\n",
    "# Load Parsed Trees\n",
    "parsed_trees_path = Path(INTERMEDIATE_DIR) / \"parsed_trees.pkl\"\n",
    "if not parsed_trees_path.exists():\n",
    "    raise FileNotFoundError(f\"Required file not found: {parsed_trees_path}\")\n",
    "\n",
    "with open(parsed_trees_path, \"rb\") as f:\n",
    "    parsed_trees = pickle.load(f)\n",
    "\n",
    "# Load Raw References\n",
    "raw_references_path = Path(INTERMEDIATE_DIR) / \"raw_references.pkl\"\n",
    "if raw_references_path.exists():\n",
    "    with open(raw_references_path, \"rb\") as f:\n",
    "        raw_references = pickle.load(f)\n",
    "else:\n",
    "    raw_references = {}\n",
    "\n",
    "# Load arXiv References Database\n",
    "arxiv_references = {}\n",
    "\n",
    "for pub_id in tqdm(parsed_trees, desc=\"STEP 1: Loading arXiv database\", unit=\"pub\"):\n",
    "    pub_folder = Path(RAW_ROOT) / pub_id[\"publication_id\"]\n",
    "    ref_path = pub_folder / \"references.json\"\n",
    "    \n",
    "    if ref_path.exists():\n",
    "        with open(ref_path, 'r', encoding='utf-8') as f:\n",
    "            refs = json.load(f)\n",
    "            # Convert dict to list format with arxiv_id\n",
    "            ref_list = [\n",
    "                {'arxiv_id': arxiv_id, **ref_data} \n",
    "                for arxiv_id, ref_data in refs.items()\n",
    "            ]\n",
    "            arxiv_references[pub_id[\"publication_id\"]] = ref_list\n",
    "\n",
    "# Summary\n",
    "total_raw_refs = sum(len(refs) for refs in raw_references.values())\n",
    "total_arxiv = sum(len(refs) for refs in arxiv_references.values())\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"STEP 1: Data Loading Complete\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"  Total publications: {len(parsed_trees)}\")\n",
    "print(f\"  Raw references: {total_raw_refs}\")\n",
    "print(f\"  arXiv entries: {total_arxiv}\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf668100",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **STEP 2 - Tree Standardization & Deduplication**\n",
    "\n",
    "Normalize, assign IDs, and deduplicate content trees across versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c22aebc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ef331919d064b118e4dc50568c380e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "STEP 2: Processing trees:   0%|          | 0/29 [00:00<?, ?pub/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a34a9221a544a308f08051a50af0bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "STEP 2: Deduplicating references:   0%|          | 0/24 [00:00<?, ?pub/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STEP 2 Complete: 29 publications standardized, 1946 unique references\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STEP 2: Tree Standardization & Deduplication\n",
    "=============================================\n",
    "Normalize, assign IDs, and merge multiple versions into single tree.\n",
    "\"\"\"\n",
    "\n",
    "# Group trees by publication\n",
    "pub_groups = defaultdict(list)\n",
    "for item in parsed_trees:\n",
    "    pub_groups[item[\"publication_id\"]].append(item)\n",
    "\n",
    "# Normalize, deduplicate, and assign IDs\n",
    "final_trees = {}\n",
    "\n",
    "for pub_id, versions in tqdm(pub_groups.items(), desc=\"STEP 2: Processing trees\", unit=\"pub\"):\n",
    "    # Sort versions by version number (v1, v2, ...)\n",
    "    versions.sort(key=lambda x: int(x[\"version\"].split(\"v\")[-1]))\n",
    "    \n",
    "    # Use first version as base\n",
    "    base = versions[0]\n",
    "    base_root = base[\"root\"]\n",
    "    \n",
    "    # Normalize content\n",
    "    normalize_node(base_root)\n",
    "    \n",
    "    # Assign global IDs\n",
    "    assign_ids(base_root, pub_id, base[\"version\"])\n",
    "    \n",
    "    # Build content index for deduplication\n",
    "    content_index = build_content_index(base_root)\n",
    "    \n",
    "    # Merge remaining versions into base\n",
    "    for v in versions[1:]:\n",
    "        root = v[\"root\"]\n",
    "        normalize_node(root)\n",
    "        assign_ids(root, pub_id, v[\"version\"])\n",
    "        deduplicate_tree(\n",
    "            target_root=base_root,\n",
    "            source_root=root,\n",
    "            content_index=content_index\n",
    "        )\n",
    "    \n",
    "    final_trees[pub_id] = base_root\n",
    "\n",
    "# Deduplicate references\n",
    "final_references = {}\n",
    "reference_id_counter = 1\n",
    "\n",
    "for pub_id in tqdm(raw_references.keys(), desc=\"STEP 2: Deduplicating references\", unit=\"pub\"):\n",
    "    refs = raw_references[pub_id]\n",
    "    deduplicated = deduplicate_references(refs)\n",
    "    \n",
    "    # Assign unique global IDs\n",
    "    for ref in deduplicated:\n",
    "        ref['ref_id'] = f\"REF-{reference_id_counter:06d}\"\n",
    "        reference_id_counter += 1\n",
    "    \n",
    "    final_references[pub_id] = deduplicated\n",
    "\n",
    "# Summary\n",
    "total_unique_refs = sum(len(refs) for refs in final_references.values())\n",
    "\n",
    "print(f\"\\nSTEP 2 Complete: {len(final_trees)} publications standardized, {total_unique_refs} unique references\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04380ff9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **STEP 3 - Reference Cleaning & Normalization**\n",
    "\n",
    "Clean and normalize BibTeX and arXiv references for matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "921404bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0851f2b07f4c91922a48f6aaf304f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "STEP 3: Cleaning BibTeX:   0%|          | 0/24 [00:00<?, ?pub/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a2e56d05eb746b9a16e0a8e511b402a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "STEP 3: Cleaning arXiv:   0%|          | 0/29 [00:00<?, ?pub/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STEP 3 Complete: 1946 BibTeX entries cleaned, 781 arXiv entries cleaned\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STEP 3: Reference Cleaning & Normalization\n",
    "===========================================\n",
    "Apply text normalization to BibTeX and arXiv references.\n",
    "\"\"\"\n",
    "\n",
    "# Clean BibTeX references\n",
    "cleaned_bibtex = {}\n",
    "\n",
    "for pub_id in tqdm(final_references.keys(), desc=\"STEP 3: Cleaning BibTeX\", unit=\"pub\"):\n",
    "    cleaned_entries = []\n",
    "    for ref in final_references[pub_id]:\n",
    "        cleaned_ref = clean_bibtex_entry(ref)\n",
    "        # Preserve original metadata\n",
    "        cleaned_ref['ref_id'] = ref['ref_id']\n",
    "        cleaned_ref['key'] = ref.get('key', '')\n",
    "        cleaned_entries.append(cleaned_ref)\n",
    "    cleaned_bibtex[pub_id] = cleaned_entries\n",
    "\n",
    "# Clean arXiv references\n",
    "cleaned_arxiv = {}\n",
    "\n",
    "for pub_id in tqdm(arxiv_references.keys(), desc=\"STEP 3: Cleaning arXiv\", unit=\"pub\"):\n",
    "    cleaned_entries = []\n",
    "    for ref in arxiv_references[pub_id]:\n",
    "        cleaned_ref = clean_arxiv_reference(ref)\n",
    "        cleaned_entries.append(cleaned_ref)\n",
    "    cleaned_arxiv[pub_id] = cleaned_entries\n",
    "\n",
    "# Summary\n",
    "total_bibtex_cleaned = sum(len(refs) for refs in cleaned_bibtex.values())\n",
    "total_arxiv_cleaned = sum(len(refs) for refs in cleaned_arxiv.values())\n",
    "\n",
    "print(f\"\\nSTEP 3 Complete: {total_bibtex_cleaned} BibTeX entries cleaned, {total_arxiv_cleaned} arXiv entries cleaned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89694df2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **STEP 4 - Labeling & Dataset Construction**\n",
    "\n",
    "Generate labeled dataset using heuristic matching and manual ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fda7c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 4.1: Processing MANUAL Labels (Exhaustive Negative Sampling)\n",
      "================================================================================\n",
      "\n",
      "  Manual Positives: 21\n",
      "  Manual Negatives (Exhaustive): 1126\n",
      "  Negative/Positive Ratio: 53.6:1\n",
      "  Total Manual Pairs: 1147\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STEP 4.1: Manual Labeling Process (Exhaustive Negative Sampling)\n",
    "=================================================================\n",
    "Generate ground truth from hardcoded manual data.\n",
    "Strategy: For each Reference, create 1 Positive + ALL Negatives from arXiv pool.\n",
    "\"\"\"\n",
    "\n",
    "# Fixed manual labels (Priority 1 - Ground Truth)\n",
    "FIXED_MANUAL_DATA = {\n",
    "    \"2211-13768\": {\n",
    "        \"2008MNRAS.391.1685S\": \"0809-0898\",\n",
    "        \"2014MNRAS.441.3359D\": \"1402-7073\",\n",
    "        \"2021MNRAS.503..920C\": \"2007-02958\",\n",
    "        \"2022arXiv220405981K\": \"2204-05981\",\n",
    "        \"Agrawal11611004611\": \"1610-04611\"\n",
    "    },\n",
    "    \"2211-13757\": {\n",
    "        \"3DiM\": \"2210-04628\",\n",
    "        \"acronym\": \"2011-09584\",\n",
    "        \"attention\": \"1706-03762\",\n",
    "        \"autosdf\": \"2203-09516\",\n",
    "        \"cascaded-point-completion\": \"2004-03327\"\n",
    "    },\n",
    "    \"2211-13767\": {\n",
    "        \"Bapat2018\": \"1812-02746\",\n",
    "        \"Bittel_2021\": \"2101-07267\",\n",
    "        \"Brady2021\": \"2107-01218\",\n",
    "        \"Crosson_2021\": \"2008-09913\",\n",
    "        \"Farhi2016\": \"1602-07674\"\n",
    "    },\n",
    "    \"2211-13755\": {\n",
    "        \"AANet\": \"2004-09548\",\n",
    "        \"ACVNet\": \"2203-02146\",\n",
    "        \"AcfNet\": \"1909-03751\",\n",
    "        \"AnyNet\": \"1810-11408\",\n",
    "        \"BI3D\": \"2005-07274\"\n",
    "    },\n",
    "    \"2211-13766\": {\n",
    "        \"BittencourtDamping2022\": \"2301-11920\",\n",
    "        \"Marius_Schrodinger_2022\": \"2211-00449\",\n",
    "        \"asjad2022magnon\": \"2203-10767\",\n",
    "        \"bourcin2022strong\": \"2209-14643\",\n",
    "        \"chan2011laser\": \"1106-3614\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(\"STEP 4.1: Processing MANUAL Labels (Exhaustive Negative Sampling)\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "manual_pairs = []\n",
    "\n",
    "# Process each manual label\n",
    "for pub_id, labels in FIXED_MANUAL_DATA.items():\n",
    "    arxiv_pool = cleaned_arxiv.get(pub_id, [])\n",
    "    if not arxiv_pool:\n",
    "        continue\n",
    "    \n",
    "    for bib_key, positive_arxiv_id in labels.items():\n",
    "        # Find cleaned entries\n",
    "        bib_entry = next((e for e in cleaned_bibtex.get(pub_id, []) if e.get('key') == bib_key), None)\n",
    "        if not bib_entry:\n",
    "            continue\n",
    "        \n",
    "        # Common BibTeX fields\n",
    "        bib_base = {\n",
    "            'pub_id': pub_id,\n",
    "            'bib_key': bib_key,\n",
    "            'bib_ref_id': bib_entry.get('ref_id', ''),\n",
    "            'bib_title_clean': bib_entry.get('normalized_title', ''),\n",
    "            'bib_authors_clean': ', '.join(bib_entry.get('normalized_authors', [])),\n",
    "            'bib_author_tokens': bib_entry.get('author_tokens', []),\n",
    "            'bib_year': bib_entry.get('normalized_year', ''),\n",
    "            'source': 'manual'\n",
    "        }\n",
    "        \n",
    "        # 1. CREATE POSITIVE PAIR (Label = 1)\n",
    "        positive_arxiv = next((e for e in arxiv_pool if e.get('arxiv_id') == positive_arxiv_id), None)\n",
    "        if positive_arxiv:\n",
    "            manual_pairs.append({\n",
    "                **bib_base,\n",
    "                'candidate_arxiv_id': positive_arxiv_id,\n",
    "                'candidate_title_clean': positive_arxiv.get('normalized_title', ''),\n",
    "                'candidate_authors_clean': ', '.join(positive_arxiv.get('normalized_authors', [])),\n",
    "                'candidate_author_tokens': positive_arxiv.get('author_tokens', []),\n",
    "                'candidate_year': positive_arxiv.get('normalized_year', ''),\n",
    "                'label': 1,\n",
    "                'pair_type': 'positive_manual'\n",
    "            })\n",
    "        \n",
    "        # 2. CREATE ALL NEGATIVE PAIRS (Exhaustive)\n",
    "        negative_arxiv_pool = [a for a in arxiv_pool if a.get('arxiv_id') != positive_arxiv_id]\n",
    "        \n",
    "        for neg_arxiv in negative_arxiv_pool:\n",
    "            neg_scores = calculate_similarity_components(bib_entry, neg_arxiv)\n",
    "            manual_pairs.append({\n",
    "                **bib_base,\n",
    "                'candidate_arxiv_id': neg_arxiv.get('arxiv_id', ''),\n",
    "                'candidate_title_clean': neg_arxiv.get('normalized_title', ''),\n",
    "                'candidate_authors_clean': ', '.join(neg_arxiv.get('normalized_authors', [])),\n",
    "                'candidate_author_tokens': neg_arxiv.get('author_tokens', []),\n",
    "                'candidate_year': neg_arxiv.get('normalized_year', ''),\n",
    "                'label': 0,\n",
    "                'pair_type': 'exhaustive_negative'\n",
    "            })\n",
    "\n",
    "# Statistics\n",
    "manual_pos = sum(1 for p in manual_pairs if p['label'] == 1)\n",
    "manual_neg = sum(1 for p in manual_pairs if p['label'] == 0)\n",
    "\n",
    "print(f\"\\n  Manual Positives: {manual_pos}\")\n",
    "print(f\"  Manual Negatives (Exhaustive): {manual_neg}\")\n",
    "print(f\"  Negative/Positive Ratio: {manual_neg/manual_pos:.1f}:1\")\n",
    "print(f\"  Total Manual Pairs: {len(manual_pairs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a86cc8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 4.2: Adaptive AUTOMATIC Matching (10% Quota + Exhaustive Negatives)\n",
      "================================================================================\n",
      "  Total references: 1946\n",
      "  Target automatic pairs (10%): 194\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82701480b3743f8882dd4100d5c20a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collecting potential matches:   0%|          | 0/24 [00:00<?, ?pub/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Selected 194 automatic matches\n",
      "  Score range: [0.956 - 1.000]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "264b017fa6af4ab09619ebb474121d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating exhaustive auto pairs:   0%|          | 0/194 [00:00<?, ?match/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Automatic Positives: 194\n",
      "  Automatic Negatives (Exhaustive): 7816\n",
      "  Negative/Positive Ratio: 40.3:1\n",
      "  Total Automatic Pairs: 8010\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STEP 4.2: Adaptive Automatic Matching (Exhaustive Negative Sampling)\n",
    "=====================================================================\n",
    "Enforce 10% quota using adaptive thresholds.\n",
    "Strategy: For each matched Reference, create 1 Positive + ALL Negatives.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(\"STEP 4.2: Adaptive AUTOMATIC Matching (10% Quota + Exhaustive Negatives)\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# 1. Calculate Quota\n",
    "total_references = sum(len(refs) for refs in cleaned_bibtex.values())\n",
    "manual_ref_ids = set((m['pub_id'], m['bib_ref_id']) for m in manual_pairs if m['label'] == 1)\n",
    "target_auto_count = int(total_references * 0.10)\n",
    "\n",
    "print(f\"  Total references: {total_references}\")\n",
    "print(f\"  Target automatic pairs (10%): {target_auto_count}\")\n",
    "\n",
    "# 2. Collect ALL potential matches\n",
    "all_potential_matches = []\n",
    "for pub_id in tqdm(cleaned_bibtex.keys(), desc=\"Collecting potential matches\", unit=\"pub\"):\n",
    "    if pub_id not in cleaned_arxiv:\n",
    "        continue\n",
    "    \n",
    "    arxiv_pool = cleaned_arxiv[pub_id]\n",
    "    \n",
    "    for bib_entry in cleaned_bibtex[pub_id]:\n",
    "        if (pub_id, bib_entry.get('ref_id', '')) in manual_ref_ids:\n",
    "            continue\n",
    "        \n",
    "        # Find best match using module function\n",
    "        best_match = find_best_match(bib_entry, arxiv_pool, threshold=0.0)\n",
    "        \n",
    "        if best_match:\n",
    "            arxiv_id, score, breakdown = best_match\n",
    "            best_arxiv = next(a for a in arxiv_pool if a['arxiv_id'] == arxiv_id)\n",
    "            if score > 0.6:  # Minimum sanity threshold\n",
    "                all_potential_matches.append({\n",
    "                    'pub_id': pub_id,\n",
    "                    'bib_entry': bib_entry,\n",
    "                    'best_arxiv': best_arxiv,\n",
    "                    'positive_arxiv_id': arxiv_id,\n",
    "                    'arxiv_pool': arxiv_pool,  # Store for negative generation\n",
    "                    'score': score,\n",
    "                    'breakdown': breakdown\n",
    "                })\n",
    "\n",
    "# 3. Apply Adaptive Threshold (Select top N matches)\n",
    "all_potential_matches.sort(key=lambda x: x['score'], reverse=True)\n",
    "selected_matches = all_potential_matches[:target_auto_count]\n",
    "\n",
    "print(f\"  Selected {len(selected_matches)} automatic matches\")\n",
    "if selected_matches:\n",
    "    print(f\"  Score range: [{selected_matches[-1]['score']:.3f} - {selected_matches[0]['score']:.3f}]\")\n",
    "\n",
    "# 4. Generate Exhaustive Pairs (Positive + ALL Negatives)\n",
    "automatic_pairs = []\n",
    "\n",
    "for match in tqdm(selected_matches, desc=\"Generating exhaustive auto pairs\", unit=\"match\"):\n",
    "    pub_id = match['pub_id']\n",
    "    bib = match['bib_entry']\n",
    "    positive_arxiv = match['best_arxiv']\n",
    "    positive_arxiv_id = match['positive_arxiv_id']\n",
    "    arxiv_pool = match['arxiv_pool']\n",
    "    \n",
    "    # Common BibTeX fields\n",
    "    bib_base = {\n",
    "        'pub_id': pub_id,\n",
    "        'bib_key': bib.get('key'),\n",
    "        'bib_ref_id': bib.get('ref_id'),\n",
    "        'bib_title_clean': bib.get('normalized_title'),\n",
    "        'bib_authors_clean': ', '.join(bib.get('normalized_authors', [])),\n",
    "        'bib_author_tokens': bib.get('author_tokens', []),\n",
    "        'bib_year': bib.get('normalized_year'),\n",
    "        'source': 'automatic'\n",
    "    }\n",
    "    \n",
    "    # 1. CREATE POSITIVE PAIR (Label = 1)\n",
    "    automatic_pairs.append({\n",
    "        **bib_base,\n",
    "        'candidate_arxiv_id': positive_arxiv_id,\n",
    "        'candidate_title_clean': positive_arxiv.get('normalized_title'),\n",
    "        'candidate_authors_clean': ', '.join(positive_arxiv.get('normalized_authors', [])),\n",
    "        'candidate_author_tokens': positive_arxiv.get('author_tokens', []),\n",
    "        'candidate_year': positive_arxiv.get('normalized_year'),\n",
    "        'label': 1,\n",
    "        'pair_type': 'positive_auto'\n",
    "    })\n",
    "    \n",
    "    # 2. CREATE ALL NEGATIVE PAIRS (Exhaustive)\n",
    "    negative_arxiv_pool = [a for a in arxiv_pool if a.get('arxiv_id') != positive_arxiv_id]\n",
    "    \n",
    "    for neg_arxiv in negative_arxiv_pool:\n",
    "        neg_scores = calculate_similarity_components(bib, neg_arxiv)\n",
    "        automatic_pairs.append({\n",
    "            **bib_base,\n",
    "            'candidate_arxiv_id': neg_arxiv.get('arxiv_id'),\n",
    "            'candidate_title_clean': neg_arxiv.get('normalized_title'),\n",
    "            'candidate_authors_clean': ', '.join(neg_arxiv.get('normalized_authors', [])),\n",
    "            'candidate_author_tokens': neg_arxiv.get('author_tokens', []),\n",
    "            'candidate_year': neg_arxiv.get('normalized_year'),\n",
    "            'label': 0,\n",
    "            'pair_type': 'exhaustive_negative'\n",
    "        })\n",
    "\n",
    "# Statistics\n",
    "auto_pos = sum(1 for p in automatic_pairs if p['label'] == 1)\n",
    "auto_neg = sum(1 for p in automatic_pairs if p['label'] == 0)\n",
    "\n",
    "print(f\"\\n  Automatic Positives: {auto_pos}\")\n",
    "print(f\"  Automatic Negatives (Exhaustive): {auto_neg}\")\n",
    "print(f\"  Negative/Positive Ratio: {auto_neg/auto_pos:.1f}:1\")\n",
    "print(f\"  Total Automatic Pairs: {len(automatic_pairs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e987bf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 4.3: Final Dataset Assembly (Exhaustive Negative Strategy)\n",
      "================================================================================\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "  FINAL DATASET STATISTICS (EXHAUSTIVE NEGATIVE SAMPLING)\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "  Total pairs: 9,157\n",
      "  Positive samples: 215\n",
      "  Negative samples: 8,942\n",
      "  Negative/Positive Ratio: 41.6:1\n",
      "\n",
      "  Manual source: 1,147 pairs\n",
      "  Automatic source: 8,010 pairs\n",
      "\n",
      "  QUOTA CHECK:\n",
      "  Target (10% of references): 194\n",
      "  Actual automatic positives: 194\n",
      "  Status: ✓ QUOTA MET\n",
      "\n",
      "  SCHEMA INFO:\n",
      "  Total columns: 14\n",
      "  Columns: ['pub_id', 'bib_key', 'bib_title_clean', 'bib_authors_clean', 'bib_author_tokens', 'bib_year', 'candidate_arxiv_id', 'candidate_title_clean', 'candidate_authors_clean', 'candidate_author_tokens', 'candidate_year', 'source', 'pair_type', 'label']\n",
      "================================================================================\n",
      "\n",
      "  ⚠️  NOTE: Class Imbalance is EXPECTED with Exhaustive Sampling.\n",
      "  This reflects real-world Citation Matching scenario (1 correct : N incorrect).\n",
      "  ✓ Score columns removed: confidence_score, title_score, author_score, year_score\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STEP 4.3: Final Dataset Assembly (Exhaustive Negative Strategy)\n",
    "================================================================\n",
    "Combine, Shuffle, and Validate Quotas.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"STEP 4.3: Final Dataset Assembly (Exhaustive Negative Strategy)\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# 1. Combine\n",
    "all_pairs = manual_pairs + automatic_pairs\n",
    "labeled_data = pd.DataFrame(all_pairs)\n",
    "\n",
    "# 2. Define Final Schema (Raw Features + Label ONLY)\n",
    "# Remove all debug score columns (confidence_score, title_score, author_score, year_score)\n",
    "final_columns = [\n",
    "    'pub_id', 'bib_key',\n",
    "    'bib_title_clean', 'bib_authors_clean', 'bib_author_tokens', 'bib_year',\n",
    "    'candidate_arxiv_id', 'candidate_title_clean', \n",
    "    'candidate_authors_clean', 'candidate_author_tokens', 'candidate_year',\n",
    "    'source', 'pair_type',\n",
    "    'label'  # Label at the end\n",
    "]\n",
    "\n",
    "# 3. Select & Reorder Columns (Keep only final schema)\n",
    "labeled_data = labeled_data[[c for c in final_columns if c in labeled_data.columns]]\n",
    "\n",
    "# 4. Shuffle Dataset\n",
    "labeled_data = labeled_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# 5. Validation Stats\n",
    "total = len(labeled_data)\n",
    "pos = len(labeled_data[labeled_data['label'] == 1])\n",
    "neg = len(labeled_data[labeled_data['label'] == 0])\n",
    "auto_pos = len(labeled_data[(labeled_data['source'] == 'automatic') & (labeled_data['label'] == 1)])\n",
    "quota_met = auto_pos >= target_auto_count\n",
    "\n",
    "print(f\"\\n{'─'*80}\")\n",
    "print(f\"  FINAL DATASET STATISTICS (EXHAUSTIVE NEGATIVE SAMPLING)\")\n",
    "print(f\"{'─'*80}\")\n",
    "print(f\"  Total pairs: {total:,}\")\n",
    "print(f\"  Positive samples: {pos:,}\")\n",
    "print(f\"  Negative samples: {neg:,}\")\n",
    "print(f\"  Negative/Positive Ratio: {neg/pos:.1f}:1\")\n",
    "print(f\"\\n  Manual source: {len(labeled_data[labeled_data['source'] == 'manual']):,} pairs\")\n",
    "print(f\"  Automatic source: {len(labeled_data[labeled_data['source'] == 'automatic']):,} pairs\")\n",
    "print(f\"\\n  QUOTA CHECK:\")\n",
    "print(f\"  Target (10% of references): {target_auto_count}\")\n",
    "print(f\"  Actual automatic positives: {auto_pos}\")\n",
    "print(f\"  Status: {'✓ QUOTA MET' if quota_met else '✗ QUOTA NOT MET'}\")\n",
    "print(f\"\\n  SCHEMA INFO:\")\n",
    "print(f\"  Total columns: {len(labeled_data.columns)}\")\n",
    "print(f\"  Columns: {list(labeled_data.columns)}\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\n  ⚠️  NOTE: Class Imbalance is EXPECTED with Exhaustive Sampling.\")\n",
    "print(f\"  This reflects real-world Citation Matching scenario (1 correct : N incorrect).\")\n",
    "print(f\"  ✓ Score columns removed: confidence_score, title_score, author_score, year_score\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea5e6ee",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **STEP 5 - Export Results**\n",
    "\n",
    "Export structured JSON files and labeled dataset for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24f7f563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed310b895a0d496291679ae90a51a4df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "STEP 5: Exporting JSON:   0%|          | 0/29 [00:00<?, ?pub/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 5: Export Complete\n",
      "================================================================================\n",
      "  Submission folder: ../22127XXX/\n",
      "  Content trees exported: 29\n",
      "  Metadata files exported: 29\n",
      "  Labeled dataset: intermediate\\labeled_dataset.csv (9157 rows)\n",
      "  Intermediate pickles: 4 files saved\n",
      "================================================================================\n",
      "\n",
      "  Note: pred.json files will be generated in Notebook 03 (Modeling)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STEP 5: Export Results\n",
    "=======================\n",
    "Export files following submission folder structure.\n",
    "\"\"\"\n",
    "\n",
    "def serialize_node(node: Any) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Recursively serialize node to dict with CLEANED text only.\n",
    "    Prioritizes node.full_text (cleaned) over node.content (raw LaTeX).\n",
    "    \"\"\"\n",
    "    # Priority: full_text (cleaned) > content (fallback) > empty\n",
    "    text_content = \"\"\n",
    "    if hasattr(node, 'full_text') and node.full_text:\n",
    "        text_content = node.full_text\n",
    "    elif hasattr(node, 'content') and node.content:\n",
    "        # Fallback: clean raw content if full_text not available\n",
    "        text_content = cleanup_latex(node.content)\n",
    "    \n",
    "    # Build base node data\n",
    "    node_data = {\n",
    "        \"id\": getattr(node, 'id', ''),\n",
    "        \"type\": getattr(node, 'node_type', 'unknown'),\n",
    "        \"text\": text_content,\n",
    "    }\n",
    "    \n",
    "    # Type-specific fields (already cleaned by normalize_node)\n",
    "    if node.node_type in {\"section\", \"subsection\", \"subsubsection\"}:\n",
    "        if hasattr(node, \"title\") and node.title:\n",
    "            node_data[\"title\"] = node.title\n",
    "    \n",
    "    if node.node_type in {\"figure\", \"table\"}:\n",
    "        if hasattr(node, \"caption\") and node.caption:\n",
    "            caption = node.caption\n",
    "            if '\\\\' in caption:  # Safety check\n",
    "                caption = cleanup_latex(caption)\n",
    "            node_data[\"caption\"] = caption\n",
    "        \n",
    "        if hasattr(node, \"label\") and node.label:\n",
    "            label = node.label\n",
    "            if '\\\\' in label:  # Safety check\n",
    "                label = cleanup_latex(label)\n",
    "            node_data[\"label\"] = label\n",
    "    \n",
    "    # Recursive children\n",
    "    if hasattr(node, 'children') and node.children:\n",
    "        node_data[\"children\"] = [serialize_node(child) for child in node.children]\n",
    "    else:\n",
    "        node_data[\"children\"] = []\n",
    "    \n",
    "    return node_data\n",
    "\n",
    "\n",
    "# Export structured JSON files (submission format)\n",
    "json_exported = 0\n",
    "metadata_exported = 0\n",
    "\n",
    "for pub_id, root in tqdm(final_trees.items(), desc=\"STEP 5: Exporting JSON\", unit=\"pub\"):\n",
    "    # Create subfolder for each publication\n",
    "    pub_folder = Path(OUTPUT_DIR) / pub_id\n",
    "    pub_folder.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # 1. Export content tree: <pub_id>/<pub_id>.json\n",
    "    content_json = {\n",
    "        \"publication_id\": pub_id,\n",
    "        \"content_tree\": serialize_node(root)\n",
    "    }\n",
    "    \n",
    "    output_json = pub_folder / f\"{pub_id}.json\"\n",
    "    with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(content_json, f, ensure_ascii=False, indent=2)\n",
    "    json_exported += 1\n",
    "    \n",
    "    # 2. Export metadata: <pub_id>/metadata.json\n",
    "    raw_metadata = Path(RAW_ROOT) / pub_id / \"metadata.json\"\n",
    "    if raw_metadata.exists():\n",
    "        with open(raw_metadata, 'r', encoding='utf-8') as f:\n",
    "            metadata = json.load(f)\n",
    "        output_metadata = pub_folder / \"metadata.json\"\n",
    "        with open(output_metadata, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "        metadata_exported += 1\n",
    "\n",
    "# Export labeled dataset for modeling (CSV)\n",
    "csv_output = Path(INTERMEDIATE_DIR) / \"labeled_dataset.csv\"\n",
    "labeled_data.to_csv(csv_output, index=False, encoding='utf-8')\n",
    "\n",
    "# Save intermediate pickle files\n",
    "with open(f\"{INTERMEDIATE_DIR}/cleaned_bibtex.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cleaned_bibtex, f)\n",
    "\n",
    "with open(f\"{INTERMEDIATE_DIR}/cleaned_arxiv.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cleaned_arxiv, f)\n",
    "\n",
    "with open(f\"{INTERMEDIATE_DIR}/final_trees.pkl\", \"wb\") as f:\n",
    "    pickle.dump(final_trees, f)\n",
    "\n",
    "with open(f\"{INTERMEDIATE_DIR}/final_references.pkl\", \"wb\") as f:\n",
    "    pickle.dump(final_references, f)\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"STEP 5: Export Complete\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"  Submission folder: {OUTPUT_DIR}/\")\n",
    "print(f\"  Content trees exported: {json_exported}\")\n",
    "print(f\"  Metadata files exported: {metadata_exported}\")\n",
    "print(f\"  Labeled dataset: {csv_output} ({len(labeled_data)} rows)\")\n",
    "print(f\"  Intermediate pickles: 4 files saved\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\n  Note: pred.json files will be generated in Notebook 03 (Modeling)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
