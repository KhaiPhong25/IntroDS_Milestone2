{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c08ea80b",
   "metadata": {},
   "source": [
    "## **Configuration & Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c6a66e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports loaded successfully\n",
      "Configuration: RAW_ROOT='../30-paper', INTERMEDIATE_DIR='intermediate', OUTPUT_DIR='../22127XXX'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Configuration & Imports\n",
    "========================\n",
    "Load all required modules and set pipeline configuration.\n",
    "\"\"\"\n",
    "\n",
    "# Standard Library\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "# Add src directory to Python path\n",
    "current_dir = os.getcwd()\n",
    "if current_dir not in sys.path:\n",
    "    sys.path.insert(0, current_dir)\n",
    "\n",
    "# Third-party\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Project Modules - Parser\n",
    "from parser.node_normalizer import normalize_node, cleanup_latex\n",
    "from parser.id_assigner import assign_ids\n",
    "from parser.content_index import build_content_index\n",
    "from parser.deduplicator import deduplicate_tree\n",
    "from parser.reference_extractor import deduplicate_references\n",
    "\n",
    "# Project Modules - Matcher\n",
    "from matcher.reference_cleaner import clean_bibtex_entry, clean_arxiv_reference\n",
    "from matcher.reference_matcher import find_best_match, calculate_similarity_components, find_hard_negative\n",
    "\n",
    "# Configuration\n",
    "RAW_ROOT = \"../30-paper\"\n",
    "INTERMEDIATE_DIR = \"intermediate\"\n",
    "STUDENT_ID = \"22127XXX\"  # TODO: Change to your student ID\n",
    "OUTPUT_DIR = f\"../{STUDENT_ID}\"  # Submission folder structure\n",
    "MANUAL_LABELS_FILE = \"manual_groundtruth.json\"\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(INTERMEDIATE_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"All imports loaded successfully\")\n",
    "print(f\"Configuration: RAW_ROOT='{RAW_ROOT}', INTERMEDIATE_DIR='{INTERMEDIATE_DIR}', OUTPUT_DIR='{OUTPUT_DIR}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2ec9e2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **STEP 1 - Load Intermediate Data**\n",
    "\n",
    "Load parsed trees, references, and arXiv database from previous pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d733f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3f848befac415d8ab13c828be1c88a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "STEP 1: Loading arXiv database:   0%|          | 0/42 [00:00<?, ?pub/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 1: Data Loading Complete\n",
      "================================================================================\n",
      "  Total publications: 42\n",
      "  Raw references: 1946\n",
      "  arXiv entries: 781\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STEP 1: Load Intermediate Data\n",
    "================================\n",
    "Load parsed trees and references from Parser Core pipeline.\n",
    "\"\"\"\n",
    "\n",
    "# Load Parsed Trees\n",
    "parsed_trees_path = Path(INTERMEDIATE_DIR) / \"parsed_trees.pkl\"\n",
    "if not parsed_trees_path.exists():\n",
    "    raise FileNotFoundError(f\"Required file not found: {parsed_trees_path}\")\n",
    "\n",
    "with open(parsed_trees_path, \"rb\") as f:\n",
    "    parsed_trees = pickle.load(f)\n",
    "\n",
    "# Load Raw References\n",
    "raw_references_path = Path(INTERMEDIATE_DIR) / \"raw_references.pkl\"\n",
    "if raw_references_path.exists():\n",
    "    with open(raw_references_path, \"rb\") as f:\n",
    "        raw_references = pickle.load(f)\n",
    "else:\n",
    "    raw_references = {}\n",
    "\n",
    "# Load arXiv References Database\n",
    "arxiv_references = {}\n",
    "\n",
    "for pub_id in tqdm(parsed_trees, desc=\"STEP 1: Loading arXiv database\", unit=\"pub\"):\n",
    "    pub_folder = Path(RAW_ROOT) / pub_id[\"publication_id\"]\n",
    "    ref_path = pub_folder / \"references.json\"\n",
    "    \n",
    "    if ref_path.exists():\n",
    "        with open(ref_path, 'r', encoding='utf-8') as f:\n",
    "            refs = json.load(f)\n",
    "            # Convert dict to list format with arxiv_id\n",
    "            ref_list = [\n",
    "                {'arxiv_id': arxiv_id, **ref_data} \n",
    "                for arxiv_id, ref_data in refs.items()\n",
    "            ]\n",
    "            arxiv_references[pub_id[\"publication_id\"]] = ref_list\n",
    "\n",
    "# Summary\n",
    "total_raw_refs = sum(len(refs) for refs in raw_references.values())\n",
    "total_arxiv = sum(len(refs) for refs in arxiv_references.values())\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"STEP 1: Data Loading Complete\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"  Total publications: {len(parsed_trees)}\")\n",
    "print(f\"  Raw references: {total_raw_refs}\")\n",
    "print(f\"  arXiv entries: {total_arxiv}\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf668100",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **STEP 2 - Tree Standardization & Deduplication**\n",
    "\n",
    "Normalize, assign IDs, and deduplicate content trees across versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c22aebc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0ea2c38f2344c108bd4bd6caeb2a55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "STEP 2: Processing trees:   0%|          | 0/29 [00:00<?, ?pub/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e0e52f8a7eb44108f95331a6e79da66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "STEP 2: Deduplicating references:   0%|          | 0/24 [00:00<?, ?pub/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STEP 2 Complete: 29 publications standardized, 1946 unique references\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STEP 2: Tree Standardization & Deduplication\n",
    "=============================================\n",
    "Normalize, assign IDs, and merge multiple versions into single tree.\n",
    "\"\"\"\n",
    "\n",
    "# Group trees by publication\n",
    "pub_groups = defaultdict(list)\n",
    "for item in parsed_trees:\n",
    "    pub_groups[item[\"publication_id\"]].append(item)\n",
    "\n",
    "# Normalize, deduplicate, and assign IDs\n",
    "final_trees = {}\n",
    "\n",
    "for pub_id, versions in tqdm(pub_groups.items(), desc=\"STEP 2: Processing trees\", unit=\"pub\"):\n",
    "    # Sort versions by version number (v1, v2, ...)\n",
    "    versions.sort(key=lambda x: int(x[\"version\"].split(\"v\")[-1]))\n",
    "    \n",
    "    # Use first version as base\n",
    "    base = versions[0]\n",
    "    base_root = base[\"root\"]\n",
    "    \n",
    "    # Normalize content\n",
    "    normalize_node(base_root)\n",
    "    \n",
    "    # Assign global IDs\n",
    "    assign_ids(base_root, pub_id, base[\"version\"])\n",
    "    \n",
    "    # Build content index for deduplication\n",
    "    content_index = build_content_index(base_root)\n",
    "    \n",
    "    # Merge remaining versions into base\n",
    "    for v in versions[1:]:\n",
    "        root = v[\"root\"]\n",
    "        normalize_node(root)\n",
    "        assign_ids(root, pub_id, v[\"version\"])\n",
    "        deduplicate_tree(\n",
    "            target_root=base_root,\n",
    "            source_root=root,\n",
    "            content_index=content_index\n",
    "        )\n",
    "    \n",
    "    final_trees[pub_id] = base_root\n",
    "\n",
    "# Deduplicate references\n",
    "final_references = {}\n",
    "reference_id_counter = 1\n",
    "\n",
    "for pub_id in tqdm(raw_references.keys(), desc=\"STEP 2: Deduplicating references\", unit=\"pub\"):\n",
    "    refs = raw_references[pub_id]\n",
    "    deduplicated = deduplicate_references(refs)\n",
    "    \n",
    "    # Assign unique global IDs\n",
    "    for ref in deduplicated:\n",
    "        ref['ref_id'] = f\"REF-{reference_id_counter:06d}\"\n",
    "        reference_id_counter += 1\n",
    "    \n",
    "    final_references[pub_id] = deduplicated\n",
    "\n",
    "# Summary\n",
    "total_unique_refs = sum(len(refs) for refs in final_references.values())\n",
    "\n",
    "print(f\"\\nSTEP 2 Complete: {len(final_trees)} publications standardized, {total_unique_refs} unique references\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04380ff9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **STEP 3 - Reference Cleaning & Normalization**\n",
    "\n",
    "Clean and normalize BibTeX and arXiv references for matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "921404bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc7dd7fcc1b407799c7babd85fb6aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "STEP 3: Cleaning BibTeX:   0%|          | 0/24 [00:00<?, ?pub/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f43cfa6a3545389c4ce027aaceb71b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "STEP 3: Cleaning arXiv:   0%|          | 0/29 [00:00<?, ?pub/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STEP 3 Complete: 1946 BibTeX entries cleaned, 781 arXiv entries cleaned\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STEP 3: Reference Cleaning & Normalization\n",
    "===========================================\n",
    "Apply text normalization to BibTeX and arXiv references.\n",
    "\"\"\"\n",
    "\n",
    "# Clean BibTeX references\n",
    "cleaned_bibtex = {}\n",
    "\n",
    "for pub_id in tqdm(final_references.keys(), desc=\"STEP 3: Cleaning BibTeX\", unit=\"pub\"):\n",
    "    cleaned_entries = []\n",
    "    for ref in final_references[pub_id]:\n",
    "        cleaned_ref = clean_bibtex_entry(ref)\n",
    "        # Preserve original metadata\n",
    "        cleaned_ref['ref_id'] = ref['ref_id']\n",
    "        cleaned_ref['key'] = ref.get('key', '')\n",
    "        cleaned_entries.append(cleaned_ref)\n",
    "    cleaned_bibtex[pub_id] = cleaned_entries\n",
    "\n",
    "# Clean arXiv references\n",
    "cleaned_arxiv = {}\n",
    "\n",
    "for pub_id in tqdm(arxiv_references.keys(), desc=\"STEP 3: Cleaning arXiv\", unit=\"pub\"):\n",
    "    cleaned_entries = []\n",
    "    for ref in arxiv_references[pub_id]:\n",
    "        cleaned_ref = clean_arxiv_reference(ref)\n",
    "        cleaned_entries.append(cleaned_ref)\n",
    "    cleaned_arxiv[pub_id] = cleaned_entries\n",
    "\n",
    "# Summary\n",
    "total_bibtex_cleaned = sum(len(refs) for refs in cleaned_bibtex.values())\n",
    "total_arxiv_cleaned = sum(len(refs) for refs in cleaned_arxiv.values())\n",
    "\n",
    "print(f\"\\nSTEP 3 Complete: {total_bibtex_cleaned} BibTeX entries cleaned, {total_arxiv_cleaned} arXiv entries cleaned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89694df2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **STEP 4 - Labeling & Dataset Construction**\n",
    "\n",
    "Generate labeled dataset using heuristic matching and manual ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fda7c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 4.1: Processing MANUAL Labels\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c5f26ef6a8a476b9ed7424fdd40b463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating manual negatives: 0pair [00:00, ?pair/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Manual Positives: 0 | Manual Negatives: 0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STEP 4.1: Manual Labeling Process\n",
    "==================================\n",
    "Generate ground truth from hardcoded manual data.\n",
    "Includes both Positive and Negative pairs for manual entries.\n",
    "\"\"\"\n",
    "\n",
    "# Fixed manual labels (Priority 1 - Ground Truth)\n",
    "FIXED_MANUAL_DATA = {\n",
    "    \"2211.13748\": {\n",
    "        \"vaswani2017attention\": \"1706.03762\",\n",
    "        \"devlin2019bert\": \"1810.04805\",\n",
    "        \"radford2018improving\": \"2005.14165\",\n",
    "        \"brown2020language\": \"2005.14165\",\n",
    "        \"raffel2020exploring\": \"1910.10683\"\n",
    "    },\n",
    "    \"2211.13750\": {\n",
    "        \"he2016deep\": \"1512.03385\",\n",
    "        \"ren2015faster\": \"1506.01497\",\n",
    "        \"lin2017feature\": \"1612.03144\",\n",
    "        \"redmon2016you\": \"1506.02640\"\n",
    "    },\n",
    "    \"2211.13752\": {\n",
    "        \"sutskever2014sequence\": \"1409.3215\",\n",
    "        \"bahdanau2015neural\": \"1409.0473\",\n",
    "        \"cho2014learning\": \"1406.1078\",\n",
    "        \"luong2015effective\": \"1508.04025\",\n",
    "        \"wu2016google\": \"1609.08144\"\n",
    "    },\n",
    "    \"2211.13755\": {\n",
    "        \"kingma2015adam\": \"1412.6980\",\n",
    "        \"glorot2010understanding\": \"1502.01852\",\n",
    "        \"he2015delving\": \"1502.01852\",\n",
    "        \"ioffe2015batch\": \"1502.03167\"\n",
    "    },\n",
    "    \"2211.13758\": {\n",
    "        \"goodfellow2014generative\": \"1406.2661\",\n",
    "        \"radford2016unsupervised\": \"1511.06434\",\n",
    "        \"arjovsky2017wasserstein\": \"1701.07875\",\n",
    "        \"gulrajani2017improved\": \"1704.00028\",\n",
    "        \"karras2019style\": \"1812.04948\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(\"STEP 4.1: Processing MANUAL Labels\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "manual_pairs = []\n",
    "\n",
    "# 1. Create POSITIVE manual pairs\n",
    "for pub_id, labels in FIXED_MANUAL_DATA.items():\n",
    "    for bib_key, arxiv_id in labels.items():\n",
    "        # Find cleaned entries\n",
    "        bib_entry = next((e for e in cleaned_bibtex.get(pub_id, []) if e.get('key') == bib_key), None)\n",
    "        arxiv_entry = next((e for e in cleaned_arxiv.get(pub_id, []) if e.get('arxiv_id') == arxiv_id), None)\n",
    "        \n",
    "        if bib_entry and arxiv_entry:\n",
    "            scores = calculate_similarity_components(bib_entry, arxiv_entry)\n",
    "            manual_pairs.append({\n",
    "                'pub_id': pub_id,\n",
    "                'bib_key': bib_key,\n",
    "                'bib_ref_id': bib_entry.get('ref_id', ''),\n",
    "                'bib_title_clean': bib_entry.get('normalized_title', ''),\n",
    "                'bib_authors_clean': ', '.join(bib_entry.get('normalized_authors', [])),\n",
    "                'bib_year': bib_entry.get('normalized_year', ''),\n",
    "                'candidate_arxiv_id': arxiv_id,\n",
    "                'candidate_title_clean': arxiv_entry.get('normalized_title', ''),\n",
    "                'candidate_authors_clean': ', '.join(arxiv_entry.get('normalized_authors', [])),\n",
    "                'candidate_year': arxiv_entry.get('normalized_year', ''),\n",
    "                'label': 1,\n",
    "                'confidence_score': scores['total_score'],\n",
    "                'title_score': scores.get('title_score', 0.0),\n",
    "                'author_score': scores.get('author_score', 0.0),\n",
    "                'year_score': scores.get('year_score', 0.0),\n",
    "                'source': 'manual',\n",
    "                'pair_type': 'positive_manual'\n",
    "            })\n",
    "\n",
    "# 2. Create NEGATIVE manual pairs (Balancing)\n",
    "manual_negative_pairs = []\n",
    "random.seed(42)\n",
    "\n",
    "for manual_pair in tqdm(manual_pairs, desc=\"Creating manual negatives\", unit=\"pair\"):\n",
    "    pub_id = manual_pair['pub_id']\n",
    "    positive_arxiv_id = manual_pair['candidate_arxiv_id']\n",
    "    \n",
    "    bib_entry = next((e for e in cleaned_bibtex.get(pub_id, []) if e.get('ref_id') == manual_pair['bib_ref_id']), None)\n",
    "    if not bib_entry: continue\n",
    "    \n",
    "    arxiv_pool = cleaned_arxiv.get(pub_id, [])\n",
    "    \n",
    "    # Try hard negative -> Fallback random\n",
    "    hard_neg_result = find_hard_negative(bib_entry, arxiv_pool, positive_arxiv_id)\n",
    "    \n",
    "    if hard_neg_result:\n",
    "        neg_arxiv, neg_scores = hard_neg_result\n",
    "        pair_type = 'hard_negative'\n",
    "    else:\n",
    "        available = [a for a in arxiv_pool if a.get('arxiv_id') != positive_arxiv_id]\n",
    "        if not available: continue\n",
    "        neg_arxiv = random.choice(available)\n",
    "        neg_scores = calculate_similarity_components(bib_entry, neg_arxiv)\n",
    "        pair_type = 'random_negative'\n",
    "    \n",
    "    manual_negative_pairs.append({\n",
    "        'pub_id': pub_id,\n",
    "        'bib_key': manual_pair['bib_key'],\n",
    "        'bib_ref_id': manual_pair['bib_ref_id'],\n",
    "        'bib_title_clean': manual_pair['bib_title_clean'],\n",
    "        'bib_authors_clean': manual_pair['bib_authors_clean'],\n",
    "        'bib_year': manual_pair['bib_year'],\n",
    "        'candidate_arxiv_id': neg_arxiv.get('arxiv_id', ''),\n",
    "        'candidate_title_clean': neg_arxiv.get('normalized_title', ''),\n",
    "        'candidate_authors_clean': ', '.join(neg_arxiv.get('normalized_authors', [])),\n",
    "        'candidate_year': neg_arxiv.get('normalized_year', ''),\n",
    "        'label': 0,\n",
    "        'confidence_score': neg_scores['total_score'],\n",
    "        'title_score': neg_scores.get('title_score', 0.0),\n",
    "        'author_score': neg_scores.get('author_score', 0.0),\n",
    "        'year_score': neg_scores.get('year_score', 0.0),\n",
    "        'source': 'manual',\n",
    "        'pair_type': pair_type\n",
    "    })\n",
    "\n",
    "print(f\"\\n  Manual Positives: {len(manual_pairs)} | Manual Negatives: {len(manual_negative_pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a86cc8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 4.2: Adaptive AUTOMATIC Matching (10% Quota Enforcement)\n",
      "================================================================================\n",
      "  Total references: 1946\n",
      "  Target automatic pairs (10%): 194\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2579aec36846cd89777760782037d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collecting potential matches:   0%|          | 0/24 [00:00<?, ?pub/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Selected 83 automatic matches\n",
      "  Score range: [0.609 - 1.000]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792fbfe51d4b402eaf9630103c8e88d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating auto pairs:   0%|          | 0/83 [00:00<?, ?match/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "STEP 4.2: Adaptive Automatic Matching\n",
    "======================================\n",
    "Enforce 10% quota using adaptive thresholds.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(\"STEP 4.2: Adaptive AUTOMATIC Matching (10% Quota Enforcement)\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# 1. Calculate Quota\n",
    "total_references = sum(len(refs) for refs in cleaned_bibtex.values())\n",
    "manual_ref_ids = set((m['pub_id'], m['bib_ref_id']) for m in manual_pairs)\n",
    "target_auto_count = int(total_references * 0.10)\n",
    "\n",
    "print(f\"  Total references: {total_references}\")\n",
    "print(f\"  Target automatic pairs (10%): {target_auto_count}\")\n",
    "\n",
    "# 2. Collect ALL potential matches\n",
    "all_potential_matches = []\n",
    "for pub_id in tqdm(cleaned_bibtex.keys(), desc=\"Collecting potential matches\", unit=\"pub\"):\n",
    "    if pub_id not in cleaned_arxiv: continue\n",
    "    \n",
    "    for bib_entry in cleaned_bibtex[pub_id]:\n",
    "        if (pub_id, bib_entry.get('ref_id', '')) in manual_ref_ids: continue\n",
    "        \n",
    "        # Find best match using module function\n",
    "        best_match = find_best_match(bib_entry, cleaned_arxiv[pub_id], threshold=0.0) # Get best regardless of score\n",
    "        \n",
    "        if best_match:\n",
    "            arxiv_id, score, breakdown = best_match\n",
    "            best_arxiv = next(a for a in cleaned_arxiv[pub_id] if a['arxiv_id'] == arxiv_id)\n",
    "            if score > 0.6: # Minimum sanity threshold\n",
    "                all_potential_matches.append({\n",
    "                    'pub_id': pub_id,\n",
    "                    'bib_entry': bib_entry,\n",
    "                    'best_arxiv': best_arxiv,\n",
    "                    'score': score,\n",
    "                    'breakdown': breakdown\n",
    "                })\n",
    "\n",
    "# 3. Apply Adaptive Threshold (Select top N matches)\n",
    "all_potential_matches.sort(key=lambda x: x['score'], reverse=True)\n",
    "selected_matches = all_potential_matches[:target_auto_count]\n",
    "\n",
    "print(f\"  Selected {len(selected_matches)} automatic matches\")\n",
    "if selected_matches:\n",
    "    print(f\"  Score range: [{selected_matches[-1]['score']:.3f} - {selected_matches[0]['score']:.3f}]\")\n",
    "\n",
    "# 4. Create Automatic Pairs (Positive + Negative)\n",
    "automatic_pairs = []\n",
    "threshold_stats = {'high': 0, 'med': 0, 'low': 0}\n",
    "\n",
    "for match in tqdm(selected_matches, desc=\"Generating auto pairs\", unit=\"match\"):\n",
    "    # POSITIVE PAIR\n",
    "    pub_id = match['pub_id']\n",
    "    bib = match['bib_entry']\n",
    "    arxiv = match['best_arxiv']\n",
    "    score = match['score']\n",
    "    \n",
    "    if score >= 0.9: threshold_stats['high'] += 1\n",
    "    elif score >= 0.8: threshold_stats['med'] += 1\n",
    "    else: threshold_stats['low'] += 1\n",
    "    \n",
    "    automatic_pairs.append({\n",
    "        'pub_id': pub_id, 'bib_key': bib.get('key'), 'bib_ref_id': bib.get('ref_id'),\n",
    "        'bib_title_clean': bib.get('normalized_title'), 'bib_authors_clean': ', '.join(bib.get('normalized_authors', [])), 'bib_year': bib.get('normalized_year'),\n",
    "        'candidate_arxiv_id': arxiv.get('arxiv_id'), 'candidate_title_clean': arxiv.get('normalized_title'), 'candidate_authors_clean': ', '.join(arxiv.get('normalized_authors', [])), 'candidate_year': arxiv.get('normalized_year'),\n",
    "        'label': 1, 'confidence_score': score, 'source': 'automatic', 'pair_type': 'positive_auto',\n",
    "        'title_score': match['breakdown'].get('title_score', 0), 'author_score': match['breakdown'].get('author_score', 0), 'year_score': match['breakdown'].get('year_score', 0)\n",
    "    })\n",
    "    \n",
    "    # NEGATIVE PAIR\n",
    "    arxiv_pool = cleaned_arxiv[pub_id]\n",
    "    hard_neg = find_hard_negative(bib, arxiv_pool, arxiv.get('arxiv_id'))\n",
    "    \n",
    "    if hard_neg:\n",
    "        neg_arxiv, neg_scores = hard_neg\n",
    "        pair_type = 'hard_negative'\n",
    "    else:\n",
    "        avail = [a for a in arxiv_pool if a['arxiv_id'] != arxiv.get('arxiv_id')]\n",
    "        if not avail: continue\n",
    "        neg_arxiv = random.choice(avail)\n",
    "        neg_scores = calculate_similarity_components(bib, neg_arxiv)\n",
    "        pair_type = 'random_negative'\n",
    "        \n",
    "    automatic_pairs.append({\n",
    "        'pub_id': pub_id, 'bib_key': bib.get('key'), 'bib_ref_id': bib.get('ref_id'),\n",
    "        'bib_title_clean': bib.get('normalized_title'), 'bib_authors_clean': ', '.join(bib.get('normalized_authors', [])), 'bib_year': bib.get('normalized_year'),\n",
    "        'candidate_arxiv_id': neg_arxiv.get('arxiv_id'), 'candidate_title_clean': neg_arxiv.get('normalized_title'), 'candidate_authors_clean': ', '.join(neg_arxiv.get('normalized_authors', [])), 'candidate_year': neg_arxiv.get('normalized_year'),\n",
    "        'label': 0, 'confidence_score': neg_scores['total_score'], 'source': 'automatic', 'pair_type': pair_type,\n",
    "        'title_score': neg_scores.get('title_score', 0), 'author_score': neg_scores.get('author_score', 0), 'year_score': neg_scores.get('year_score', 0)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e987bf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 4.3: Final Dataset Assembly\n",
      "================================================================================\n",
      "  Total pairs: 166\n",
      "  Positive: 83 | Negative: 83 (Ratio: 1.00)\n",
      "  Manual pairs: 0\n",
      "  Automatic pairs: 166\n",
      "\n",
      "  QUOTA CHECK:\n",
      "  Target (10%): 194 | Actual: 83\n",
      "  Status: ✗ QUOTA NOT MET\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STEP 4.3: Final Dataset Assembly\n",
    "=================================\n",
    "Combine, Shuffle, and Validate Quotas.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"STEP 4.3: Final Dataset Assembly\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# 1. Combine\n",
    "all_pairs = manual_pairs + manual_negative_pairs + automatic_pairs\n",
    "labeled_data = pd.DataFrame(all_pairs)\n",
    "\n",
    "# 2. Reorder & Shuffle\n",
    "cols = ['pub_id', 'bib_key', 'bib_ref_id', 'bib_title_clean', 'candidate_arxiv_id', 'candidate_title_clean', \n",
    "        'label', 'confidence_score', 'title_score', 'author_score', 'year_score', 'source', 'pair_type']\n",
    "labeled_data = labeled_data[[c for c in cols if c in labeled_data.columns]]\n",
    "labeled_data = labeled_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# 3. Validation Stats\n",
    "total = len(labeled_data)\n",
    "pos = len(labeled_data[labeled_data['label'] == 1])\n",
    "neg = len(labeled_data[labeled_data['label'] == 0])\n",
    "auto_pos = len(labeled_data[(labeled_data['source'] == 'automatic') & (labeled_data['label'] == 1)])\n",
    "quota_met = auto_pos >= target_auto_count\n",
    "\n",
    "print(f\"  Total pairs: {total}\")\n",
    "print(f\"  Positive: {pos} | Negative: {neg} (Ratio: {neg/pos:.2f})\")\n",
    "print(f\"  Manual pairs: {len(manual_pairs) + len(manual_negative_pairs)}\")\n",
    "print(f\"  Automatic pairs: {len(automatic_pairs)}\")\n",
    "print(f\"\\n  QUOTA CHECK:\")\n",
    "print(f\"  Target (10%): {target_auto_count} | Actual: {auto_pos}\")\n",
    "print(f\"  Status: {'✓ QUOTA MET' if quota_met else '✗ QUOTA NOT MET'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea5e6ee",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **STEP 5 - Export Results**\n",
    "\n",
    "Export structured JSON files and labeled dataset for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24f7f563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d46040ce6b1c40118123d9b6c46eb465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "STEP 5: Exporting JSON:   0%|          | 0/29 [00:00<?, ?pub/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 5: Export Complete\n",
      "================================================================================\n",
      "  Submission folder: ../22127XXX/\n",
      "  Content trees exported: 29\n",
      "  Metadata files exported: 29\n",
      "  References files exported: 29\n",
      "  Labeled dataset: intermediate\\labeled_dataset.csv (166 rows)\n",
      "  Intermediate pickles: 4 files saved\n",
      "================================================================================\n",
      "\n",
      "  Note: pred.json files will be generated in Notebook 03 (Modeling)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STEP 5: Export Results\n",
    "=======================\n",
    "Export files following submission folder structure.\n",
    "\"\"\"\n",
    "\n",
    "def serialize_node(node: Any) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Recursively serialize node to dict with CLEANED text only.\n",
    "    Prioritizes node.full_text (cleaned) over node.content (raw LaTeX).\n",
    "    \"\"\"\n",
    "    # Priority: full_text (cleaned) > content (fallback) > empty\n",
    "    text_content = \"\"\n",
    "    if hasattr(node, 'full_text') and node.full_text:\n",
    "        text_content = node.full_text\n",
    "    elif hasattr(node, 'content') and node.content:\n",
    "        # Fallback: clean raw content if full_text not available\n",
    "        text_content = cleanup_latex(node.content)\n",
    "    \n",
    "    # Build base node data\n",
    "    node_data = {\n",
    "        \"id\": getattr(node, 'id', ''),\n",
    "        \"type\": getattr(node, 'node_type', 'unknown'),\n",
    "        \"text\": text_content,\n",
    "    }\n",
    "    \n",
    "    # Type-specific fields (already cleaned by normalize_node)\n",
    "    if node.node_type in {\"section\", \"subsection\", \"subsubsection\"}:\n",
    "        if hasattr(node, \"title\") and node.title:\n",
    "            node_data[\"title\"] = node.title\n",
    "    \n",
    "    if node.node_type in {\"figure\", \"table\"}:\n",
    "        if hasattr(node, \"caption\") and node.caption:\n",
    "            caption = node.caption\n",
    "            if '\\\\' in caption:  # Safety check\n",
    "                caption = cleanup_latex(caption)\n",
    "            node_data[\"caption\"] = caption\n",
    "        \n",
    "        if hasattr(node, \"label\") and node.label:\n",
    "            label = node.label\n",
    "            if '\\\\' in label:  # Safety check\n",
    "                label = cleanup_latex(label)\n",
    "            node_data[\"label\"] = label\n",
    "    \n",
    "    # Recursive children\n",
    "    if hasattr(node, 'children') and node.children:\n",
    "        node_data[\"children\"] = [serialize_node(child) for child in node.children]\n",
    "    else:\n",
    "        node_data[\"children\"] = []\n",
    "    \n",
    "    return node_data\n",
    "\n",
    "\n",
    "# Export structured JSON files (submission format)\n",
    "json_exported = 0\n",
    "metadata_exported = 0\n",
    "references_exported = 0\n",
    "\n",
    "for pub_id, root in tqdm(final_trees.items(), desc=\"STEP 5: Exporting JSON\", unit=\"pub\"):\n",
    "    # Create subfolder for each publication\n",
    "    pub_folder = Path(OUTPUT_DIR) / pub_id\n",
    "    pub_folder.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # 1. Export content tree: <pub_id>/<pub_id>.json\n",
    "    content_json = {\n",
    "        \"publication_id\": pub_id,\n",
    "        \"content_tree\": serialize_node(root)\n",
    "    }\n",
    "    \n",
    "    output_json = pub_folder / f\"{pub_id}.json\"\n",
    "    with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(content_json, f, ensure_ascii=False, indent=2)\n",
    "    json_exported += 1\n",
    "    \n",
    "    # 2. Export metadata: <pub_id>/metadata.json\n",
    "    raw_metadata = Path(RAW_ROOT) / pub_id / \"metadata.json\"\n",
    "    if raw_metadata.exists():\n",
    "        with open(raw_metadata, 'r', encoding='utf-8') as f:\n",
    "            metadata = json.load(f)\n",
    "        output_metadata = pub_folder / \"metadata.json\"\n",
    "        with open(output_metadata, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "        metadata_exported += 1\n",
    "    \n",
    "    # 3. Export references: <pub_id>/references.json\n",
    "    references_list = final_references.get(pub_id, [])\n",
    "    output_references = pub_folder / \"references.json\"\n",
    "    with open(output_references, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(references_list, f, ensure_ascii=False, indent=2)\n",
    "    references_exported += 1\n",
    "\n",
    "# Export labeled dataset for modeling (CSV)\n",
    "csv_output = Path(INTERMEDIATE_DIR) / \"labeled_dataset.csv\"\n",
    "labeled_data.to_csv(csv_output, index=False, encoding='utf-8')\n",
    "\n",
    "# Save intermediate pickle files\n",
    "with open(f\"{INTERMEDIATE_DIR}/cleaned_bibtex.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cleaned_bibtex, f)\n",
    "\n",
    "with open(f\"{INTERMEDIATE_DIR}/cleaned_arxiv.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cleaned_arxiv, f)\n",
    "\n",
    "with open(f\"{INTERMEDIATE_DIR}/final_trees.pkl\", \"wb\") as f:\n",
    "    pickle.dump(final_trees, f)\n",
    "\n",
    "with open(f\"{INTERMEDIATE_DIR}/final_references.pkl\", \"wb\") as f:\n",
    "    pickle.dump(final_references, f)\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"STEP 5: Export Complete\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"  Submission folder: {OUTPUT_DIR}/\")\n",
    "print(f\"  Content trees exported: {json_exported}\")\n",
    "print(f\"  Metadata files exported: {metadata_exported}\")\n",
    "print(f\"  References files exported: {references_exported}\")\n",
    "print(f\"  Labeled dataset: {csv_output} ({len(labeled_data)} rows)\")\n",
    "print(f\"  Intermediate pickles: 4 files saved\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\n  Note: pred.json files will be generated in Notebook 03 (Modeling)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
